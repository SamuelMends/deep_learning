{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #importando nossa biblioteca Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsores = pd.read_csv('entradas_breast.csv') #declarando nossas variáveis de entrada\n",
    "classe = pd.read_csv('saidas_breast.csv') #declarando nossas variáveis de saida (expectativa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split #Criando os ambientes de treinamento e teste\n",
    "previsores_treinamento, previsores_teste, classe_treinamento, classe_teste = train_test_split(previsores, classe, test_size=0.25) #Declarando as variáveis de treinamento e de teste, em seguida splitando elas através do train_test_slipt, usando test_size = 25, indica que estamos utilizando apenas 25% de todos os registros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samue\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import keras #importando o Keras\n",
    "from keras.models import Sequential #Sequential é a modelo q vamos usar, possui esse nome pois é aformado pela sequência (entrada, primeira camada oculta, segunda camada oculta e saida)\n",
    "from keras.layers import Dense #Dense é o modelo de rede neural densa ou fully connected\n",
    "classificador = Sequential() #nossa rede neural se chama Sequential \n",
    "classificador.add(Dense(units=16, activation='relu', kernel_initializer='random_uniform', input_dim=30)) #Criando nossa primeira camada oculta. Units = Qtde de neuronios de entrada formula (qtde de entradas = 30 + qtde de saidas = 1) e divide por 2. O primeiro activation utilizamos o relu. Initializer é método pelo qual ele vai selecionar as entradas por isso utlizamos random. Input_dim é a qtde de elementos na camada de entrada do programa.\n",
    "classificador.add(Dense(units=16, activation='relu', kernel_initializer='random_uniform')) \n",
    "classificador.add(Dense(units=1, activation='sigmoid')) #Criando nossa camada de saida, units é a qtde de neurônios de saida e actvation nossa função de ativação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#otimizador = keras.optimizers.Adam(learning_rate = 0.001, weight_decay = 0.0001, clipvalue = 0.5)\n",
    "#classificador.compile(optimizer = otimizador, loss = 'binary_crossentropy', metrics= ['binary_accuracy'])\n",
    "classificador.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics= ['binary_accuracy']) #utilizando o otimizador ADAM para fazer o ajuste dos pesos (realiza a otimização da descida do gradiente stocastico). Loss binary crossentropy utilizamos essa função quando trabalhamos apenas com duas classes. Metrics= binary_accuracy para testar a acuracidade da nossa saida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - binary_accuracy: 0.5804 - loss: 1.3200\n",
      "Epoch 2/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - binary_accuracy: 0.6673 - loss: 0.5392\n",
      "Epoch 3/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - binary_accuracy: 0.7412 - loss: 0.4513\n",
      "Epoch 4/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - binary_accuracy: 0.7455 - loss: 0.4467\n",
      "Epoch 5/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - binary_accuracy: 0.8443 - loss: 0.4485\n",
      "Epoch 6/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - binary_accuracy: 0.8351 - loss: 0.4104\n",
      "Epoch 7/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - binary_accuracy: 0.8563 - loss: 0.3889\n",
      "Epoch 8/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.7875 - loss: 0.4388\n",
      "Epoch 9/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.8856 - loss: 0.3536\n",
      "Epoch 10/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.8363 - loss: 0.4075\n",
      "Epoch 11/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.8851 - loss: 0.3335\n",
      "Epoch 12/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.8956 - loss: 0.3087\n",
      "Epoch 13/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.8918 - loss: 0.2957\n",
      "Epoch 14/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - binary_accuracy: 0.8774 - loss: 0.3163\n",
      "Epoch 15/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.8834 - loss: 0.3089\n",
      "Epoch 16/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.8895 - loss: 0.3007\n",
      "Epoch 17/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - binary_accuracy: 0.8697 - loss: 0.3570\n",
      "Epoch 18/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9095 - loss: 0.2661\n",
      "Epoch 19/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9380 - loss: 0.2073\n",
      "Epoch 20/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.8878 - loss: 0.2817\n",
      "Epoch 21/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.8777 - loss: 0.2927\n",
      "Epoch 22/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.8938 - loss: 0.2572\n",
      "Epoch 23/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.8868 - loss: 0.2676\n",
      "Epoch 24/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9217 - loss: 0.1925\n",
      "Epoch 25/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9279 - loss: 0.2097\n",
      "Epoch 26/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9054 - loss: 0.2571\n",
      "Epoch 27/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - binary_accuracy: 0.9504 - loss: 0.1702\n",
      "Epoch 28/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9451 - loss: 0.1798\n",
      "Epoch 29/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9105 - loss: 0.2174\n",
      "Epoch 30/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9483 - loss: 0.1636\n",
      "Epoch 31/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.8987 - loss: 0.2232\n",
      "Epoch 32/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - binary_accuracy: 0.9275 - loss: 0.1879\n",
      "Epoch 33/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - binary_accuracy: 0.9501 - loss: 0.1438 \n",
      "Epoch 34/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.8765 - loss: 0.3044\n",
      "Epoch 35/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9406 - loss: 0.1922\n",
      "Epoch 36/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9160 - loss: 0.2163\n",
      "Epoch 37/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9395 - loss: 0.1516\n",
      "Epoch 38/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9037 - loss: 0.2478\n",
      "Epoch 39/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9123 - loss: 0.2053\n",
      "Epoch 40/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9280 - loss: 0.1705\n",
      "Epoch 41/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9263 - loss: 0.1907\n",
      "Epoch 42/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9266 - loss: 0.2090\n",
      "Epoch 43/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9140 - loss: 0.1923\n",
      "Epoch 44/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9362 - loss: 0.1656\n",
      "Epoch 45/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9118 - loss: 0.1980\n",
      "Epoch 46/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9282 - loss: 0.1874\n",
      "Epoch 47/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9370 - loss: 0.1667\n",
      "Epoch 48/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9304 - loss: 0.1595\n",
      "Epoch 49/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9443 - loss: 0.1477\n",
      "Epoch 50/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - binary_accuracy: 0.9242 - loss: 0.1852\n",
      "Epoch 51/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9228 - loss: 0.1977\n",
      "Epoch 52/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9409 - loss: 0.1604\n",
      "Epoch 53/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9464 - loss: 0.1480\n",
      "Epoch 54/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9276 - loss: 0.1411\n",
      "Epoch 55/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9224 - loss: 0.1834\n",
      "Epoch 56/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9512 - loss: 0.1412\n",
      "Epoch 57/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9481 - loss: 0.1528\n",
      "Epoch 58/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9431 - loss: 0.1567\n",
      "Epoch 59/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9151 - loss: 0.1633\n",
      "Epoch 60/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9148 - loss: 0.2058\n",
      "Epoch 61/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9421 - loss: 0.1560\n",
      "Epoch 62/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9240 - loss: 0.1642\n",
      "Epoch 63/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9346 - loss: 0.1456\n",
      "Epoch 64/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9350 - loss: 0.1271\n",
      "Epoch 65/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9200 - loss: 0.2110\n",
      "Epoch 66/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9364 - loss: 0.1662\n",
      "Epoch 67/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9324 - loss: 0.1490\n",
      "Epoch 68/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9499 - loss: 0.1422\n",
      "Epoch 69/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9557 - loss: 0.1305\n",
      "Epoch 70/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9001 - loss: 0.1774\n",
      "Epoch 71/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9196 - loss: 0.2092\n",
      "Epoch 72/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9286 - loss: 0.1525\n",
      "Epoch 73/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9563 - loss: 0.1227\n",
      "Epoch 74/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9539 - loss: 0.1385\n",
      "Epoch 75/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9512 - loss: 0.1020\n",
      "Epoch 76/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9315 - loss: 0.1513 \n",
      "Epoch 77/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9223 - loss: 0.1782\n",
      "Epoch 78/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9622 - loss: 0.1104\n",
      "Epoch 79/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9419 - loss: 0.1330\n",
      "Epoch 80/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9450 - loss: 0.1383\n",
      "Epoch 81/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9475 - loss: 0.1263\n",
      "Epoch 82/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9006 - loss: 0.2100\n",
      "Epoch 83/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9246 - loss: 0.1687\n",
      "Epoch 84/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9369 - loss: 0.1312\n",
      "Epoch 85/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9441 - loss: 0.1160\n",
      "Epoch 86/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9230 - loss: 0.1940\n",
      "Epoch 87/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9561 - loss: 0.1082\n",
      "Epoch 88/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9307 - loss: 0.1301\n",
      "Epoch 89/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9351 - loss: 0.1158\n",
      "Epoch 90/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9355 - loss: 0.1635\n",
      "Epoch 91/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9457 - loss: 0.1609\n",
      "Epoch 92/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9375 - loss: 0.1345\n",
      "Epoch 93/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9343 - loss: 0.1385\n",
      "Epoch 94/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9458 - loss: 0.1167\n",
      "Epoch 95/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9187 - loss: 0.1679\n",
      "Epoch 96/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9496 - loss: 0.1360\n",
      "Epoch 97/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9416 - loss: 0.1276\n",
      "Epoch 98/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9433 - loss: 0.1093\n",
      "Epoch 99/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9667 - loss: 0.1103 \n",
      "Epoch 100/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9627 - loss: 0.1161\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2277aac6180>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classificador.fit(previsores_treinamento, classe_treinamento, batch_size = 10, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 4.60039936e-02,  5.56685925e-02,  2.50988957e-02,\n",
      "         3.55637558e-02, -3.14274758e-01, -5.99779934e-03,\n",
      "        -3.63916159e-01,  4.91534732e-02,  6.79328069e-02,\n",
      "         5.40338177e-03,  3.87267172e-02,  1.23247653e-02,\n",
      "        -2.93032043e-02, -4.15206105e-02,  2.96344440e-02,\n",
      "         7.61141330e-02],\n",
      "       [-2.22613593e-03,  1.54432938e-01, -5.46880402e-02,\n",
      "        -1.13755753e-02,  1.18337683e-01,  4.95718382e-02,\n",
      "         8.52402672e-02,  7.83605501e-02, -2.87556555e-02,\n",
      "         1.46898199e-02,  1.47409633e-01,  1.30063612e-02,\n",
      "        -3.29406708e-02, -2.01073047e-02, -1.60707623e-01,\n",
      "        -4.97359335e-02],\n",
      "       [-5.35562411e-02,  9.47142988e-02,  3.77564095e-02,\n",
      "        -4.42106239e-02, -2.88471490e-01, -4.64924239e-03,\n",
      "        -3.07592094e-01,  6.54642656e-02,  2.56020963e-01,\n",
      "        -2.15813205e-01,  9.65070501e-02, -1.15525704e-02,\n",
      "        -3.23006995e-02, -1.66423898e-02, -7.05055296e-02,\n",
      "         2.84923762e-01],\n",
      "       [-2.85974964e-02,  2.49972213e-02, -6.36315569e-02,\n",
      "         1.74752418e-02, -4.65719663e-02,  5.20391914e-04,\n",
      "        -6.66452721e-02, -6.92111552e-02,  6.27405047e-02,\n",
      "        -8.34369659e-02,  1.49825879e-03, -7.50879347e-02,\n",
      "        -1.85587034e-02, -2.18756516e-02,  5.58904931e-03,\n",
      "         1.91804897e-02],\n",
      "       [-1.52278878e-02, -9.68951639e-03, -8.48246459e-03,\n",
      "         2.39492878e-02,  2.26180945e-02,  2.20556837e-02,\n",
      "         1.52946308e-01,  6.85958341e-02, -8.88093933e-02,\n",
      "         1.77984074e-01,  1.38655473e-02, -5.57569377e-02,\n",
      "        -1.30089093e-02, -4.90578935e-02,  2.53496934e-02,\n",
      "         1.35091603e-01],\n",
      "       [-1.32218199e-02,  4.86330092e-02, -6.43550009e-02,\n",
      "        -1.76416915e-02,  3.31985801e-02, -4.88259085e-02,\n",
      "         1.13300122e-01, -8.66511464e-02, -7.88342655e-02,\n",
      "         1.22001156e-01, -4.21566293e-02, -1.50075583e-02,\n",
      "        -2.04460463e-03,  6.00280464e-02,  1.42276645e-01,\n",
      "         1.27786338e-01],\n",
      "       [ 1.13500906e-02,  5.78713678e-02,  1.60470545e-01,\n",
      "        -1.63453408e-02,  1.16263494e-01, -2.66734920e-02,\n",
      "        -9.12403967e-03, -1.24696745e-02,  5.16915657e-02,\n",
      "        -5.98622113e-02, -2.34673880e-02, -1.06139734e-01,\n",
      "         4.89006676e-02,  5.89273386e-02,  1.12234153e-01,\n",
      "        -1.41315699e-01],\n",
      "       [-4.25279774e-02,  1.29172578e-01,  3.30880910e-01,\n",
      "        -5.26719242e-02, -1.21192373e-01,  9.26685855e-02,\n",
      "        -9.92106870e-02,  2.05062833e-02,  3.16566303e-02,\n",
      "        -3.89014073e-02,  2.29271740e-01, -1.80071848e-03,\n",
      "         2.52411515e-02, -6.18804395e-02, -8.85396078e-02,\n",
      "         3.00930768e-01],\n",
      "       [ 1.78175002e-01, -8.35776702e-02,  9.22520906e-02,\n",
      "         2.84387451e-02,  5.67688197e-02,  3.39397267e-02,\n",
      "        -1.78946033e-01,  1.93750665e-01, -7.20546767e-02,\n",
      "         6.46510273e-02,  9.64826271e-02,  2.60346737e-02,\n",
      "         2.75506172e-02, -3.60264033e-02, -1.27644897e-01,\n",
      "         9.41779986e-02],\n",
      "       [-1.08410195e-01,  1.10281289e-01, -6.63006380e-02,\n",
      "        -3.65823321e-02, -1.90597773e-01, -4.88164723e-02,\n",
      "        -2.64347762e-01, -1.97196275e-01,  3.87533247e-01,\n",
      "         1.26075014e-01,  2.31725112e-01, -6.86317077e-03,\n",
      "        -2.61051562e-02, -4.45094705e-03,  1.89141467e-01,\n",
      "        -3.34221125e-02],\n",
      "       [-1.30858161e-02,  2.06535198e-02, -1.68781862e-01,\n",
      "        -6.46902854e-03, -2.79770885e-02, -2.60950960e-02,\n",
      "        -3.77088375e-02, -9.10879485e-03, -9.69291627e-02,\n",
      "        -1.15954518e-01,  6.30772486e-02,  1.99003387e-02,\n",
      "         1.36085078e-02,  1.46134412e-02,  1.77886579e-02,\n",
      "         1.79207977e-02],\n",
      "       [ 1.57330390e-02, -2.04408839e-02,  3.73241752e-02,\n",
      "        -3.65547207e-03, -5.12731187e-02,  1.09236417e-02,\n",
      "        -3.92336538e-03,  3.71997505e-02, -7.14744776e-02,\n",
      "        -1.46092894e-03, -4.57980782e-02, -7.58574763e-03,\n",
      "        -1.19943898e-02,  8.17687600e-04,  1.41120143e-02,\n",
      "         3.19220424e-02],\n",
      "       [-2.70107407e-02, -2.70267762e-02,  2.40419731e-02,\n",
      "        -2.60071121e-02,  1.02636144e-02, -6.35023881e-03,\n",
      "         1.85152031e-02, -3.07460930e-02,  3.51876058e-02,\n",
      "         1.12617351e-02, -7.37938955e-02, -1.60146914e-02,\n",
      "        -4.16313410e-02, -1.54080121e-02, -8.50245655e-02,\n",
      "        -1.60667114e-02],\n",
      "       [ 4.90197130e-02,  5.33384718e-02, -9.62985680e-03,\n",
      "        -5.17385565e-02,  5.01825586e-02, -3.25167775e-02,\n",
      "         6.82198629e-02, -1.39943227e-01, -1.31289318e-01,\n",
      "         6.51825815e-02,  7.49637932e-02, -1.13405436e-02,\n",
      "        -2.92170476e-02,  8.27999189e-02,  3.30200605e-02,\n",
      "        -1.44209892e-01],\n",
      "       [ 8.69963914e-02,  8.09576735e-02, -7.80847017e-03,\n",
      "         1.64445061e-02,  1.42537057e-01, -4.24964400e-03,\n",
      "         1.41452745e-01,  2.36114025e-01, -3.03905942e-02,\n",
      "        -7.97666982e-02,  1.45137221e-01, -4.03198041e-02,\n",
      "         3.48079950e-02,  1.46453716e-02, -2.81804174e-01,\n",
      "        -6.85694516e-02],\n",
      "       [ 6.52904063e-02,  2.51176208e-02,  2.09999040e-01,\n",
      "         7.67751411e-03,  3.19864184e-01,  1.34865075e-01,\n",
      "         4.07687545e-01,  3.55881572e-01, -4.71493930e-01,\n",
      "         1.16655059e-01, -1.30888030e-01, -4.31936271e-02,\n",
      "        -1.41829392e-02,  3.15667279e-02, -3.37173402e-01,\n",
      "         4.62881893e-01],\n",
      "       [ 7.93101862e-02,  5.76869287e-02, -4.42286693e-02,\n",
      "        -2.20143441e-02, -2.53707021e-01,  1.27589013e-02,\n",
      "        -2.12497413e-01,  2.50063185e-02, -1.83160603e-01,\n",
      "        -6.60179034e-02, -6.45477250e-02, -6.62017763e-02,\n",
      "         8.69202521e-03, -6.59777895e-02,  1.37485147e-01,\n",
      "         4.35905993e-01],\n",
      "       [-1.01261094e-01,  4.28280197e-02,  8.78614560e-02,\n",
      "         1.51062813e-02, -3.83393377e-01, -4.52253073e-02,\n",
      "         7.79910460e-02,  2.43513435e-02,  3.95945609e-01,\n",
      "        -2.82514930e-01, -1.45014487e-02, -2.28090379e-02,\n",
      "        -3.36643085e-02, -2.03720964e-02,  1.02755599e-01,\n",
      "         4.13042545e-01],\n",
      "       [-1.02381960e-01,  5.24088219e-02,  1.77763775e-01,\n",
      "         5.48790023e-03, -5.44673383e-01,  3.57079580e-02,\n",
      "        -1.87857866e-01, -1.18308701e-01,  4.92607027e-01,\n",
      "        -4.51907158e-01,  8.94535035e-02, -4.75736149e-02,\n",
      "        -5.29632322e-04,  7.22365174e-03,  2.81165600e-01,\n",
      "        -1.07654124e-01],\n",
      "       [-6.00918941e-02, -5.02706245e-02, -1.19376436e-01,\n",
      "         1.40902996e-02,  3.21935773e-01, -3.64308245e-02,\n",
      "         3.49379241e-01,  1.09777804e-02, -4.32929724e-01,\n",
      "         1.73526123e-01,  4.95145693e-02,  1.56239839e-02,\n",
      "         1.38328671e-02, -3.09208222e-02,  7.37957060e-02,\n",
      "        -3.02664429e-01],\n",
      "       [ 4.63780314e-02,  5.21133393e-02,  1.00244824e-02,\n",
      "        -1.01651764e-02, -2.64613777e-01,  4.47130166e-02,\n",
      "        -1.66701943e-01,  1.82626955e-02,  2.06053391e-01,\n",
      "        -1.67094335e-01,  6.75724670e-02,  2.40686145e-02,\n",
      "        -2.85370983e-02, -1.24690635e-02, -3.21998075e-02,\n",
      "         2.92360961e-01],\n",
      "       [-3.29115950e-02,  8.63322541e-02, -1.68921113e-01,\n",
      "        -2.62145549e-02,  1.66240752e-01, -5.42991888e-03,\n",
      "         2.92252153e-01,  3.68850050e-03, -1.58551037e-01,\n",
      "         1.07685804e-01,  1.45093113e-01, -3.73002701e-02,\n",
      "        -1.12124439e-02, -2.86411084e-02, -2.20852032e-01,\n",
      "        -1.40787616e-01],\n",
      "       [ 7.20350258e-03,  2.79032476e-02, -2.30621751e-02,\n",
      "        -4.06904481e-02, -1.23287804e-01,  1.47727961e-02,\n",
      "        -1.92264885e-01, -1.19153624e-02,  1.52646169e-01,\n",
      "        -1.13192208e-01,  1.08293481e-01, -3.18759605e-02,\n",
      "        -4.65659536e-02, -3.84523161e-02, -4.16350961e-02,\n",
      "         2.04157978e-01],\n",
      "       [-2.84878686e-02, -4.32027467e-02, -1.48534000e-01,\n",
      "        -2.58471966e-02,  1.22081712e-01, -6.28101081e-02,\n",
      "         8.66712481e-02, -1.64015032e-02, -9.90289599e-02,\n",
      "         8.61646906e-02, -2.57055238e-02, -4.24503759e-02,\n",
      "         4.83121350e-03, -5.80920540e-02,  8.89863595e-02,\n",
      "        -4.68174070e-02],\n",
      "       [-2.36905720e-02, -1.03369839e-02, -6.89608604e-02,\n",
      "        -2.67703156e-03,  2.64512431e-02, -4.54450510e-02,\n",
      "         6.66317111e-03,  6.93859719e-03,  7.58744031e-02,\n",
      "        -4.59445007e-02, -7.65671255e-03,  2.16820911e-02,\n",
      "         3.82083207e-02,  4.06117737e-02, -3.01704317e-01,\n",
      "        -3.20268452e-01],\n",
      "       [ 1.13337882e-01,  8.54961351e-02,  1.35426685e-01,\n",
      "        -3.27210408e-03,  4.36175354e-02,  6.82770610e-02,\n",
      "        -2.62902994e-02,  7.20005184e-02, -2.11286712e-02,\n",
      "         5.69541976e-02,  2.09427491e-01, -3.31754647e-02,\n",
      "         4.94215451e-02,  8.00794661e-02, -1.44790590e-01,\n",
      "         2.00763885e-02],\n",
      "       [-5.51018156e-02,  7.57551268e-02, -5.07577360e-02,\n",
      "        -5.66157624e-02,  1.05563089e-01,  8.23783688e-03,\n",
      "        -2.80572087e-01, -4.41564061e-02, -3.23121995e-03,\n",
      "         1.04853012e-01,  1.36804685e-01, -6.67967945e-02,\n",
      "        -1.22868922e-02,  2.55351141e-02, -1.76180005e-01,\n",
      "         3.54891568e-02],\n",
      "       [ 2.84070838e-02,  3.88469175e-03,  2.27179583e-02,\n",
      "         1.52549343e-02,  1.40434042e-01, -2.79294234e-02,\n",
      "        -3.16582978e-01, -6.52748644e-02, -2.54697442e-01,\n",
      "        -3.19735287e-03, -4.79600765e-02, -2.91085951e-02,\n",
      "        -8.01736861e-03,  9.66095030e-02,  5.56812510e-02,\n",
      "        -2.43046451e-02],\n",
      "       [-4.77447510e-02, -2.06447933e-02, -8.07974041e-02,\n",
      "        -4.86481674e-02,  9.06582475e-02,  2.19554361e-02,\n",
      "         1.22994129e-02,  2.94886176e-02,  3.99252139e-02,\n",
      "         6.04985468e-02,  3.00931558e-02,  1.84432901e-02,\n",
      "         2.89240275e-02,  2.66894307e-02, -6.16802722e-02,\n",
      "         8.79029185e-02],\n",
      "       [ 1.24879433e-02,  2.60302443e-02, -1.24867365e-01,\n",
      "        -4.72034933e-03,  3.37304533e-01, -2.89911795e-02,\n",
      "         3.62612933e-01, -1.72564331e-02, -2.78998226e-01,\n",
      "         1.78767517e-01,  9.99639705e-02, -4.83663641e-02,\n",
      "         9.40711983e-03,  4.51043770e-02, -1.58326626e-01,\n",
      "        -2.24875689e-01]], dtype=float32), array([ 0.05109894,  0.18116722,  0.21557401, -0.00904436, -0.5454612 ,\n",
      "        0.05030858, -0.53713626,  0.15218471,  0.5632458 , -0.42417222,\n",
      "        0.24629897, -0.02216946, -0.00625945, -0.0017777 , -0.30623314,\n",
      "        0.52518785], dtype=float32)]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "pesos0 = classificador.layers[0].get_weights()\n",
    "print(pesos0)\n",
    "print(len(pesos0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000002270522FA60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 178ms/stepWARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000002270522FA60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n"
     ]
    }
   ],
   "source": [
    "previsoes = classificador.predict(previsores_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9083 - loss: 0.6341  \n"
     ]
    }
   ],
   "source": [
    "resultado = classificador.evaluate(previsores_teste, classe_teste)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
