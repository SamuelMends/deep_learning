{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #importando nossa biblioteca Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsores = pd.read_csv('entradas_breast.csv') #declarando nossas variáveis de entrada\n",
    "classe = pd.read_csv('saidas_breast.csv') #declarando nossas variáveis de saida (expectativa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split #Criando os ambientes de treinamento e teste\n",
    "previsores_treinamento, previsores_teste, classe_treinamento, classe_teste = train_test_split(previsores, classe, test_size=0.25) #Declarando as variáveis de treinamento e de teste, em seguida splitando elas através do train_test_slipt, usando test_size = 25, indica que estamos utilizando apenas 25% de todos os registros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samue\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import keras #importando o Keras\n",
    "from keras.models import Sequential #Sequential é a modelo q vamos usar, possui esse nome pois é aformado pela sequência (entrada, primeira camada oculta, segunda camada oculta e saida)\n",
    "from keras.layers import Dense #Dense é o modelo de rede neural densa ou fully connected\n",
    "classificador = Sequential() #nossa rede neural se chama Sequential \n",
    "classificador.add(Dense(units=16, activation='relu', kernel_initializer='random_uniform', input_dim=30)) #Criando nossa primeira camada oculta. Units = Qtde de neuronios de entrada formula (qtde de entradas = 30 + qtde de saidas = 1) e divide por 2. O primeiro activation utilizamos o relu. Initializer é método pelo qual ele vai selecionar as entradas por isso utlizamos random. Input_dim é a qtde de elementos na camada de entrada do programa.\n",
    "classificador.add(Dense(units=16, activation='relu', kernel_initializer='random_uniform')) \n",
    "classificador.add(Dense(units=1, activation='sigmoid')) #Criando nossa camada de saida, units é a qtde de neurônios de saida e actvation nossa função de ativação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#otimizador = keras.optimizers.Adam(learning_rate = 0.001, weight_decay = 0.0001, clipvalue = 0.5)\n",
    "#classificador.compile(optimizer = otimizador, loss = 'binary_crossentropy', metrics= ['binary_accuracy'])\n",
    "classificador.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics= ['binary_accuracy']) #utilizando o otimizador ADAM para fazer o ajuste dos pesos (realiza a otimização da descida do gradiente stocastico). Loss binary crossentropy utilizamos essa função quando trabalhamos apenas com duas classes. Metrics= binary_accuracy para testar a acuracidade da nossa saida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 913us/step - binary_accuracy: 0.5361 - loss: 0.7131\n",
      "Epoch 2/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - binary_accuracy: 0.6372 - loss: 0.5606\n",
      "Epoch 3/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step - binary_accuracy: 0.6466 - loss: 0.5151\n",
      "Epoch 4/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777us/step - binary_accuracy: 0.7505 - loss: 0.4280\n",
      "Epoch 5/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - binary_accuracy: 0.7819 - loss: 0.4392\n",
      "Epoch 6/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - binary_accuracy: 0.8236 - loss: 0.4176\n",
      "Epoch 7/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - binary_accuracy: 0.7706 - loss: 0.4250\n",
      "Epoch 8/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - binary_accuracy: 0.8053 - loss: 0.3825\n",
      "Epoch 9/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - binary_accuracy: 0.8490 - loss: 0.3615\n",
      "Epoch 10/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - binary_accuracy: 0.8402 - loss: 0.3270\n",
      "Epoch 11/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - binary_accuracy: 0.8530 - loss: 0.3208\n",
      "Epoch 12/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756us/step - binary_accuracy: 0.8876 - loss: 0.2922\n",
      "Epoch 13/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771us/step - binary_accuracy: 0.8717 - loss: 0.3066\n",
      "Epoch 14/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step - binary_accuracy: 0.8720 - loss: 0.3141\n",
      "Epoch 15/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9184 - loss: 0.2255\n",
      "Epoch 16/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - binary_accuracy: 0.9155 - loss: 0.2320\n",
      "Epoch 17/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - binary_accuracy: 0.8698 - loss: 0.2638\n",
      "Epoch 18/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - binary_accuracy: 0.9121 - loss: 0.2059\n",
      "Epoch 19/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - binary_accuracy: 0.8764 - loss: 0.2725\n",
      "Epoch 20/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - binary_accuracy: 0.9023 - loss: 0.2243\n",
      "Epoch 21/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - binary_accuracy: 0.8807 - loss: 0.2418\n",
      "Epoch 22/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - binary_accuracy: 0.9466 - loss: 0.1690\n",
      "Epoch 23/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step - binary_accuracy: 0.9341 - loss: 0.1728\n",
      "Epoch 24/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step - binary_accuracy: 0.9135 - loss: 0.1798\n",
      "Epoch 25/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - binary_accuracy: 0.9118 - loss: 0.2176\n",
      "Epoch 26/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step - binary_accuracy: 0.9352 - loss: 0.1643\n",
      "Epoch 27/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - binary_accuracy: 0.9330 - loss: 0.1964\n",
      "Epoch 28/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - binary_accuracy: 0.9587 - loss: 0.1528\n",
      "Epoch 29/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - binary_accuracy: 0.9139 - loss: 0.1876\n",
      "Epoch 30/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - binary_accuracy: 0.9042 - loss: 0.2456\n",
      "Epoch 31/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9249 - loss: 0.1885\n",
      "Epoch 32/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - binary_accuracy: 0.9140 - loss: 0.2016\n",
      "Epoch 33/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864us/step - binary_accuracy: 0.9499 - loss: 0.1420\n",
      "Epoch 34/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - binary_accuracy: 0.9425 - loss: 0.1429\n",
      "Epoch 35/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.8858 - loss: 0.2144 \n",
      "Epoch 36/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9128 - loss: 0.2078 \n",
      "Epoch 37/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - binary_accuracy: 0.9142 - loss: 0.2083\n",
      "Epoch 38/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - binary_accuracy: 0.9490 - loss: 0.1354\n",
      "Epoch 39/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - binary_accuracy: 0.9408 - loss: 0.1694\n",
      "Epoch 40/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - binary_accuracy: 0.9231 - loss: 0.1672\n",
      "Epoch 41/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9302 - loss: 0.1591 \n",
      "Epoch 42/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.8975 - loss: 0.2328\n",
      "Epoch 43/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9472 - loss: 0.1506 \n",
      "Epoch 44/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - binary_accuracy: 0.9374 - loss: 0.1582\n",
      "Epoch 45/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - binary_accuracy: 0.9410 - loss: 0.1675\n",
      "Epoch 46/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step - binary_accuracy: 0.9486 - loss: 0.1386\n",
      "Epoch 47/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9321 - loss: 0.1700 \n",
      "Epoch 48/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step - binary_accuracy: 0.9069 - loss: 0.2036\n",
      "Epoch 49/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - binary_accuracy: 0.9527 - loss: 0.1381\n",
      "Epoch 50/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9504 - loss: 0.1311 \n",
      "Epoch 51/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - binary_accuracy: 0.9283 - loss: 0.1556\n",
      "Epoch 52/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - binary_accuracy: 0.9529 - loss: 0.1282\n",
      "Epoch 53/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step - binary_accuracy: 0.9447 - loss: 0.1415\n",
      "Epoch 54/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - binary_accuracy: 0.9521 - loss: 0.1439\n",
      "Epoch 55/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - binary_accuracy: 0.9270 - loss: 0.1865\n",
      "Epoch 56/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - binary_accuracy: 0.9459 - loss: 0.1554\n",
      "Epoch 57/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - binary_accuracy: 0.9277 - loss: 0.1480\n",
      "Epoch 58/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - binary_accuracy: 0.9328 - loss: 0.1478\n",
      "Epoch 59/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step - binary_accuracy: 0.9498 - loss: 0.1265\n",
      "Epoch 60/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - binary_accuracy: 0.9363 - loss: 0.1712\n",
      "Epoch 61/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - binary_accuracy: 0.9598 - loss: 0.1101\n",
      "Epoch 62/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9564 - loss: 0.1256 \n",
      "Epoch 63/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - binary_accuracy: 0.9245 - loss: 0.1582\n",
      "Epoch 64/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - binary_accuracy: 0.9367 - loss: 0.1315\n",
      "Epoch 65/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - binary_accuracy: 0.9261 - loss: 0.1718\n",
      "Epoch 66/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - binary_accuracy: 0.9324 - loss: 0.1556\n",
      "Epoch 67/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - binary_accuracy: 0.9127 - loss: 0.1914\n",
      "Epoch 68/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - binary_accuracy: 0.9133 - loss: 0.1734\n",
      "Epoch 69/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step - binary_accuracy: 0.9473 - loss: 0.1339\n",
      "Epoch 70/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - binary_accuracy: 0.9378 - loss: 0.1367\n",
      "Epoch 71/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - binary_accuracy: 0.9416 - loss: 0.1582\n",
      "Epoch 72/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - binary_accuracy: 0.9496 - loss: 0.1234\n",
      "Epoch 73/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - binary_accuracy: 0.9376 - loss: 0.1387\n",
      "Epoch 74/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - binary_accuracy: 0.9536 - loss: 0.1132\n",
      "Epoch 75/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - binary_accuracy: 0.9548 - loss: 0.1158\n",
      "Epoch 76/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - binary_accuracy: 0.9476 - loss: 0.1291\n",
      "Epoch 77/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - binary_accuracy: 0.9527 - loss: 0.1201\n",
      "Epoch 78/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - binary_accuracy: 0.9326 - loss: 0.1422\n",
      "Epoch 79/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9355 - loss: 0.1431\n",
      "Epoch 80/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864us/step - binary_accuracy: 0.9477 - loss: 0.1207\n",
      "Epoch 81/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - binary_accuracy: 0.9414 - loss: 0.1376\n",
      "Epoch 82/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - binary_accuracy: 0.9349 - loss: 0.1248\n",
      "Epoch 83/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - binary_accuracy: 0.9337 - loss: 0.1584\n",
      "Epoch 84/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - binary_accuracy: 0.9591 - loss: 0.1128\n",
      "Epoch 85/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - binary_accuracy: 0.9426 - loss: 0.1392\n",
      "Epoch 86/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - binary_accuracy: 0.9431 - loss: 0.1134\n",
      "Epoch 87/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9603 - loss: 0.1003\n",
      "Epoch 88/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9504 - loss: 0.1074\n",
      "Epoch 89/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step - binary_accuracy: 0.9517 - loss: 0.1397\n",
      "Epoch 90/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - binary_accuracy: 0.9440 - loss: 0.1451\n",
      "Epoch 91/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - binary_accuracy: 0.9655 - loss: 0.1081\n",
      "Epoch 92/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - binary_accuracy: 0.9331 - loss: 0.1374\n",
      "Epoch 93/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - binary_accuracy: 0.9278 - loss: 0.1414\n",
      "Epoch 94/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - binary_accuracy: 0.9411 - loss: 0.1398\n",
      "Epoch 95/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - binary_accuracy: 0.9315 - loss: 0.1450\n",
      "Epoch 96/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9525 - loss: 0.1138 \n",
      "Epoch 97/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9555 - loss: 0.1040 \n",
      "Epoch 98/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9449 - loss: 0.0970 \n",
      "Epoch 99/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step - binary_accuracy: 0.9585 - loss: 0.1247\n",
      "Epoch 100/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - binary_accuracy: 0.9075 - loss: 0.2169\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x20f7d8febd0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classificador.fit(previsores_treinamento, classe_treinamento, batch_size = 10, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-3.93089764e-02,  1.73471302e-01,  4.05990100e-03,\n",
      "         3.36597413e-01,  1.41383514e-01,  1.24346003e-01,\n",
      "        -3.06958526e-01,  1.87135730e-02, -2.25820005e-01,\n",
      "        -1.64234247e-02, -6.70527108e-03,  7.46776611e-02,\n",
      "        -2.30706874e-02, -1.47287324e-01, -1.11075252e-01,\n",
      "        -5.16168587e-03],\n",
      "       [ 2.31235884e-02,  1.60603285e-01, -9.98362154e-03,\n",
      "        -8.09281599e-04,  1.96750723e-02,  5.34125157e-02,\n",
      "        -5.61767370e-02,  9.95119382e-03,  3.61535139e-02,\n",
      "         1.67842116e-02,  1.89949237e-02,  1.01393677e-01,\n",
      "        -1.52881471e-02, -1.23438582e-01,  7.72156790e-02,\n",
      "        -2.76361909e-02],\n",
      "       [ 1.39155127e-02,  1.58780023e-01,  1.94275789e-02,\n",
      "         2.42198691e-01,  1.08057961e-01,  7.25496635e-02,\n",
      "        -3.05282831e-01,  1.74239818e-02, -1.49779156e-01,\n",
      "        -2.34173704e-02,  4.95973267e-02,  2.37898026e-02,\n",
      "        -5.91384359e-02, -9.67586786e-02, -3.63161117e-02,\n",
      "        -5.99075109e-02],\n",
      "       [-4.44613956e-02,  5.31183295e-02, -2.04889402e-05,\n",
      "         4.29419801e-02,  1.75056998e-02,  4.12768051e-02,\n",
      "        -4.11769077e-02,  1.78202018e-02, -1.07964486e-01,\n",
      "        -2.94480436e-02, -1.81481466e-02, -2.37427540e-02,\n",
      "        -6.70764819e-02,  2.71120239e-02,  2.69144345e-02,\n",
      "        -1.49020385e-02],\n",
      "       [ 2.83970125e-02,  1.39313653e-01, -1.91841237e-02,\n",
      "        -2.78674625e-02, -3.71603258e-02,  4.12740633e-02,\n",
      "         1.11352555e-01, -6.10371679e-02,  7.59840384e-02,\n",
      "         2.82649230e-02, -3.85367759e-02, -1.66005492e-02,\n",
      "         4.15906087e-02, -6.06645308e-02,  5.90088516e-02,\n",
      "        -5.22373468e-02],\n",
      "       [ 3.92576568e-02,  2.84708012e-02,  2.08585450e-04,\n",
      "         1.96171757e-02,  1.95111737e-01,  4.17962717e-03,\n",
      "        -8.11263174e-02,  2.68909577e-02,  2.24825982e-02,\n",
      "        -3.95394228e-02, -9.32567171e-04, -3.58762890e-02,\n",
      "        -3.74762304e-02,  8.40965286e-02,  2.16118932e-01,\n",
      "        -4.47968133e-02],\n",
      "       [ 2.79863514e-02, -9.91247818e-02,  2.18738336e-02,\n",
      "        -7.41545185e-02,  1.28007516e-01, -8.49097148e-02,\n",
      "        -1.68975815e-02,  4.72183190e-02, -2.43184604e-02,\n",
      "        -5.17708398e-02, -3.01587004e-02,  3.15562226e-02,\n",
      "         1.95596945e-02,  6.61821589e-02,  1.44729406e-01,\n",
      "         1.42372157e-02],\n",
      "       [-4.14578319e-02,  2.60068506e-01,  2.43448000e-02,\n",
      "         1.85231254e-01, -1.33180261e-01,  3.40050608e-01,\n",
      "        -6.62531555e-02,  2.64712349e-02,  5.26445024e-02,\n",
      "         2.79567037e-02,  4.27392907e-02,  1.30175576e-01,\n",
      "        -5.21727391e-02, -1.20533697e-01, -3.14600736e-01,\n",
      "        -1.21046737e-01],\n",
      "       [-2.82109734e-02,  1.22155093e-01,  1.64794251e-01,\n",
      "        -1.60907656e-02,  1.04591057e-01,  1.94226339e-01,\n",
      "         2.87525430e-02, -2.75197141e-02, -2.68201321e-01,\n",
      "        -5.81712909e-02,  6.74346015e-02,  4.06183116e-02,\n",
      "        -6.14349954e-02, -1.77741423e-01, -1.07947998e-01,\n",
      "        -3.70024629e-02],\n",
      "       [ 1.74867548e-02,  2.27470999e-03, -1.95621960e-02,\n",
      "        -7.46917352e-02,  2.19314948e-01, -7.53891766e-02,\n",
      "         2.22400557e-02,  3.78766060e-02,  1.99491661e-02,\n",
      "        -5.20154797e-02,  6.53775856e-02,  2.60539293e-01,\n",
      "        -6.69110660e-03,  1.80809811e-01, -2.87076592e-01,\n",
      "         3.92606333e-02],\n",
      "       [ 3.63506377e-04,  1.58281937e-01, -5.31527027e-02,\n",
      "        -5.97811751e-02,  2.77663451e-02,  5.26054949e-02,\n",
      "         3.44151072e-02,  1.09446347e-02, -4.71584760e-02,\n",
      "        -5.83980121e-02, -6.14106935e-03,  5.60113154e-02,\n",
      "        -3.98877934e-02, -8.43438087e-04,  1.00646816e-01,\n",
      "         1.06843084e-01],\n",
      "       [-2.73378137e-02,  4.92464416e-02,  6.63592480e-03,\n",
      "         6.73766434e-03, -3.47580947e-02,  2.45250277e-02,\n",
      "         7.88850710e-03,  8.17767251e-03,  2.17925441e-02,\n",
      "         1.03083942e-02, -5.15588224e-02, -3.77783440e-02,\n",
      "         2.76894141e-02,  4.37219860e-03, -3.34629230e-02,\n",
      "         5.95993455e-03],\n",
      "       [-1.83351636e-02, -5.66811115e-02, -1.19626829e-02,\n",
      "         2.83347443e-02,  2.43883883e-03, -3.41686085e-02,\n",
      "        -1.91418955e-03, -2.95428559e-02,  1.64878257e-02,\n",
      "        -5.11411466e-02, -9.14433822e-02, -8.10211599e-02,\n",
      "        -3.93584706e-02, -8.34961385e-02,  1.02270823e-02,\n",
      "        -2.95538250e-02],\n",
      "       [-3.22774649e-02, -1.33406579e-01,  1.24147579e-01,\n",
      "        -3.32214504e-01, -5.67987114e-02, -1.30612150e-01,\n",
      "         1.40244454e-01, -8.93817097e-03,  1.68592691e-01,\n",
      "        -6.43643960e-02, -2.64602248e-02,  1.07762650e-01,\n",
      "        -5.26665114e-02,  7.38546485e-04, -7.36819580e-03,\n",
      "         4.54370193e-02],\n",
      "       [ 4.25074957e-02,  4.89013717e-02, -3.03912014e-02,\n",
      "         8.54561403e-02,  5.80288395e-02,  4.61039692e-03,\n",
      "        -1.48595423e-01,  1.02865314e-02, -3.89564596e-02,\n",
      "         2.02379264e-02,  7.07484176e-03,  9.17411223e-02,\n",
      "         1.75441224e-02, -9.35872570e-02,  1.30183071e-01,\n",
      "         3.55036347e-03],\n",
      "       [ 4.14261855e-02,  2.87180841e-01,  1.13823868e-01,\n",
      "         2.56576419e-01, -6.96309879e-02,  1.08589984e-01,\n",
      "        -2.28383213e-01,  3.29895020e-02, -6.13799691e-02,\n",
      "        -3.64684835e-02, -1.30725861e-01, -1.08038455e-01,\n",
      "         3.90164442e-02, -2.89013088e-01, -6.56445771e-02,\n",
      "        -1.14298863e-02],\n",
      "       [ 9.17930529e-03,  3.37810367e-01, -5.21365777e-02,\n",
      "         1.04155384e-01,  1.04602925e-01,  1.37621000e-01,\n",
      "        -6.93931207e-02,  1.81929313e-03, -5.63559681e-02,\n",
      "        -4.12942097e-02, -8.33996534e-02, -1.05995513e-01,\n",
      "        -4.52141948e-02,  7.89254084e-02, -1.84160266e-02,\n",
      "         5.02992310e-02],\n",
      "       [ 5.07288054e-03,  1.98200062e-01, -3.81337292e-02,\n",
      "         2.97525972e-01,  1.28267169e-01,  4.72008698e-02,\n",
      "        -1.99227408e-01,  2.77388263e-02,  2.45414108e-01,\n",
      "        -3.23441951e-03,  1.60304353e-01,  1.05827108e-01,\n",
      "         1.81612447e-02, -2.56839216e-01,  3.84654105e-02,\n",
      "        -1.34551823e-02],\n",
      "       [ 2.34950893e-02, -2.94664055e-01, -3.49484906e-02,\n",
      "        -2.44480371e-01,  3.26299489e-01, -2.13194460e-01,\n",
      "        -9.11948830e-02,  2.03316193e-02,  1.39464602e-01,\n",
      "        -2.78637297e-02, -1.68425050e-02,  4.77959476e-02,\n",
      "         2.93688923e-02,  4.61688489e-01,  5.90177953e-01,\n",
      "        -8.97013247e-02],\n",
      "       [-5.46679646e-03, -1.42299935e-01, -5.23426756e-02,\n",
      "        -5.08215845e-01,  1.14575528e-01, -2.02261448e-01,\n",
      "         5.42801559e-01,  9.34997573e-03,  2.48573929e-01,\n",
      "         3.17683374e-03, -6.17935993e-02, -8.43131728e-03,\n",
      "        -3.78941162e-03,  1.90224975e-01,  3.55609775e-01,\n",
      "         1.19697163e-02],\n",
      "       [-1.18493810e-02,  1.59578830e-01, -5.04799653e-03,\n",
      "         1.98857546e-01,  6.56091943e-02,  1.71606727e-02,\n",
      "        -2.69396096e-01, -1.70817915e-02, -1.10594861e-01,\n",
      "        -1.94077156e-02, -1.69606898e-02,  5.08586364e-03,\n",
      "        -2.49264669e-02, -1.51236504e-01, -7.73777300e-03,\n",
      "        -3.99380401e-02],\n",
      "       [ 7.76680559e-03,  5.39305545e-02, -6.31582811e-02,\n",
      "        -9.58718136e-02, -5.70047311e-02, -6.69738231e-03,\n",
      "         6.57720864e-02, -3.85397300e-02,  1.67582199e-01,\n",
      "        -5.65563440e-02,  3.04998476e-02,  3.05165537e-02,\n",
      "        -3.91805843e-02, -2.41118088e-01,  7.66590610e-02,\n",
      "        -6.53146505e-02],\n",
      "       [ 2.96596177e-02,  2.97147967e-02, -3.10368259e-02,\n",
      "         1.93470329e-01,  4.67256345e-02, -8.32477957e-03,\n",
      "        -1.51354179e-01, -3.97681892e-02, -4.16053608e-02,\n",
      "         3.79009135e-02,  1.35288322e-02, -1.31994486e-02,\n",
      "        -4.68987413e-02, -7.36800134e-02, -3.20189632e-02,\n",
      "         2.01563840e-03],\n",
      "       [-3.97536866e-02,  1.42946392e-02, -8.16688016e-02,\n",
      "        -8.35840181e-02, -1.19883502e-02, -6.95867762e-02,\n",
      "         1.20062284e-01, -5.48168942e-02,  8.57634246e-02,\n",
      "        -1.51337031e-02, -6.93078106e-03, -4.51840833e-02,\n",
      "        -5.86042255e-02,  6.39898926e-02,  4.44498919e-02,\n",
      "        -1.91139877e-02],\n",
      "       [-2.98822280e-02,  1.63658544e-01, -1.01609612e-02,\n",
      "        -5.74762560e-02,  7.84340948e-02,  8.62974450e-02,\n",
      "         3.38656865e-02, -1.04377111e-02, -8.94847885e-02,\n",
      "        -4.64465097e-02,  2.35439762e-02,  4.95670363e-02,\n",
      "         4.66081873e-02, -1.28295586e-01,  3.19432288e-01,\n",
      "        -1.61904171e-02],\n",
      "       [ 1.88084580e-02,  2.74603404e-02,  2.12268401e-02,\n",
      "        -5.78051768e-05,  1.00375354e-01, -5.23474254e-02,\n",
      "         3.58501859e-02, -4.04939316e-02, -2.26307027e-02,\n",
      "        -8.27066693e-03,  7.73556679e-02,  5.08001857e-02,\n",
      "        -4.29132953e-02, -1.12774983e-01, -1.20728873e-01,\n",
      "        -2.33765859e-02],\n",
      "       [ 4.96144779e-02, -1.41234562e-01, -6.11568764e-02,\n",
      "         5.24620758e-03,  1.36307523e-01, -4.98051755e-02,\n",
      "         2.76530404e-02, -5.23220934e-02, -3.26209247e-01,\n",
      "         2.54741497e-02,  9.85098183e-02,  1.71213187e-02,\n",
      "        -2.17722580e-02, -1.76840454e-01, -1.38502583e-01,\n",
      "        -2.28610989e-02],\n",
      "       [-1.80553086e-02,  2.24401265e-01, -7.42259026e-02,\n",
      "         4.37621847e-02,  5.07673956e-02,  3.11508705e-03,\n",
      "         9.20803472e-02, -2.60787178e-02, -1.31154090e-01,\n",
      "         2.34147459e-02, -2.91320086e-02, -2.63683908e-02,\n",
      "        -6.46443442e-02,  2.19122265e-02, -1.87279016e-01,\n",
      "         9.64351371e-03],\n",
      "       [-1.72613487e-02, -1.75262257e-01, -6.63987026e-02,\n",
      "        -7.13149682e-02,  7.11667016e-02, -2.08512438e-03,\n",
      "        -2.07180027e-02, -3.56733240e-02, -8.93361773e-03,\n",
      "         5.54029364e-03,  1.28892846e-02,  2.00863257e-01,\n",
      "         1.44708075e-03, -1.47482976e-01, -1.65987841e-03,\n",
      "        -2.51546018e-02],\n",
      "       [-6.28299639e-03, -1.22656941e-01, -5.07872105e-02,\n",
      "        -2.51179218e-01,  1.10927984e-01, -1.11585245e-01,\n",
      "         2.90476233e-01, -1.70214735e-02,  1.17990576e-01,\n",
      "        -2.31684037e-02,  7.39420578e-02,  5.05126938e-02,\n",
      "        -1.85494833e-02,  9.61704403e-02,  2.14434713e-01,\n",
      "         9.90821607e-03]], dtype=float32), array([ 0.        ,  0.27262726,  0.07074815,  0.5641919 ,  0.14495456,\n",
      "        0.14156991, -0.5800542 , -0.0132192 , -0.33555642, -0.00912534,\n",
      "        0.08047033,  0.11009331, -0.00492365, -0.25692728, -0.20166625,\n",
      "       -0.05400638], dtype=float32)]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "pesos0 = classificador.layers[0].get_weights()\n",
    "print(pesos0)\n",
    "print(len(pesos0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n"
     ]
    }
   ],
   "source": [
    "previsoes = classificador.predict(previsores_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9135 - loss: 0.2075  \n"
     ]
    }
   ],
   "source": [
    "resultado = classificador.evaluate(previsores_teste, classe_teste)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
