{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #importando nossa biblioteca Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsores = pd.read_csv('entradas_breast.csv') #declarando nossas variáveis de entrada\n",
    "classe = pd.read_csv('saidas_breast.csv') #declarando nossas variáveis de saida (expectativa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split #Criando os ambientes de treinamento e teste\n",
    "previsores_treinamento, previsores_teste, classe_treinamento, classe_teste = train_test_split(previsores, classe, test_size=0.25) #Declarando as variáveis de treinamento e de teste, em seguida splitando elas através do train_test_slipt, usando test_size = 25, indica que estamos utilizando apenas 25% de todos os registros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samue\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import keras #importando o Keras\n",
    "from keras.models import Sequential #Sequential é a modelo q vamos usar, possui esse nome pois é aformado pela sequência (entrada, primeira camada oculta, segunda camada oculta e saida)\n",
    "from keras.layers import Dense #Dense é o modelo de rede neural densa ou fully connected\n",
    "classificador = Sequential() #nossa rede neural se chama Sequential \n",
    "classificador.add(Dense(units=16, activation='relu', kernel_initializer='random_uniform', input_dim=30)) #Criando nossa primeira camada oculta. Units = Qtde de neuronios de entrada formula (qtde de entradas = 30 + qtde de saidas = 1) e divide por 2. O primeiro activation utilizamos o relu. Initializer é método pelo qual ele vai selecionar as entradas por isso utlizamos random. Input_dim é a qtde de elementos na camada de entrada do programa.\n",
    "classificador.add(Dense(units=16, activation='relu', kernel_initializer='random_uniform')) \n",
    "classificador.add(Dense(units=1, activation='sigmoid')) #Criando nossa camada de saida, units é a qtde de neurônios de saida e actvation nossa função de ativação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#otimizador = keras.optimizers.Adam(learning_rate = 0.001, weight_decay = 0.0001, clipvalue = 0.5)\n",
    "#classificador.compile(optimizer = otimizador, loss = 'binary_crossentropy', metrics= ['binary_accuracy'])\n",
    "classificador.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics= ['binary_accuracy']) #utilizando o otimizador ADAM para fazer o ajuste dos pesos (realiza a otimização da descida do gradiente stocastico). Loss binary crossentropy utilizamos essa função quando trabalhamos apenas com duas classes. Metrics= binary_accuracy para testar a acuracidade da nossa saida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - binary_accuracy: 0.6273 - loss: 2.1560\n",
      "Epoch 2/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - binary_accuracy: 0.6852 - loss: 0.5103\n",
      "Epoch 3/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step - binary_accuracy: 0.7515 - loss: 0.4591\n",
      "Epoch 4/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - binary_accuracy: 0.8330 - loss: 0.3936\n",
      "Epoch 5/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - binary_accuracy: 0.8585 - loss: 0.3528\n",
      "Epoch 6/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - binary_accuracy: 0.8252 - loss: 0.3628\n",
      "Epoch 7/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - binary_accuracy: 0.7609 - loss: 0.4860\n",
      "Epoch 8/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - binary_accuracy: 0.7562 - loss: 0.4700\n",
      "Epoch 9/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - binary_accuracy: 0.8459 - loss: 0.3315\n",
      "Epoch 10/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - binary_accuracy: 0.9045 - loss: 0.2980\n",
      "Epoch 11/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.8829 - loss: 0.2883\n",
      "Epoch 12/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.8289 - loss: 0.3312\n",
      "Epoch 13/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9001 - loss: 0.2438\n",
      "Epoch 14/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - binary_accuracy: 0.8803 - loss: 0.2545\n",
      "Epoch 15/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - binary_accuracy: 0.9027 - loss: 0.2385\n",
      "Epoch 16/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.8960 - loss: 0.2584 \n",
      "Epoch 17/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9044 - loss: 0.2308 \n",
      "Epoch 18/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9021 - loss: 0.2007\n",
      "Epoch 19/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.8937 - loss: 0.2145 \n",
      "Epoch 20/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9562 - loss: 0.1687 \n",
      "Epoch 21/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9027 - loss: 0.2256\n",
      "Epoch 22/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.8645 - loss: 0.2898\n",
      "Epoch 23/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.8937 - loss: 0.2384\n",
      "Epoch 24/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step - binary_accuracy: 0.9127 - loss: 0.2106\n",
      "Epoch 25/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - binary_accuracy: 0.8990 - loss: 0.2301\n",
      "Epoch 26/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step - binary_accuracy: 0.9204 - loss: 0.1975\n",
      "Epoch 27/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - binary_accuracy: 0.9059 - loss: 0.2263\n",
      "Epoch 28/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - binary_accuracy: 0.8723 - loss: 0.2203\n",
      "Epoch 29/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - binary_accuracy: 0.9255 - loss: 0.1999\n",
      "Epoch 30/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step - binary_accuracy: 0.9453 - loss: 0.1527\n",
      "Epoch 31/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9250 - loss: 0.1630 \n",
      "Epoch 32/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9337 - loss: 0.1829 \n",
      "Epoch 33/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - binary_accuracy: 0.8855 - loss: 0.3068\n",
      "Epoch 34/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9293 - loss: 0.1732 \n",
      "Epoch 35/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9349 - loss: 0.1923\n",
      "Epoch 36/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9291 - loss: 0.1887 \n",
      "Epoch 37/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9337 - loss: 0.1583 \n",
      "Epoch 38/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - binary_accuracy: 0.9073 - loss: 0.1906\n",
      "Epoch 39/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9130 - loss: 0.1716 \n",
      "Epoch 40/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - binary_accuracy: 0.9427 - loss: 0.1349\n",
      "Epoch 41/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9566 - loss: 0.1509 \n",
      "Epoch 42/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9103 - loss: 0.1712\n",
      "Epoch 43/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - binary_accuracy: 0.9502 - loss: 0.1488\n",
      "Epoch 44/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9231 - loss: 0.1566 \n",
      "Epoch 45/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9241 - loss: 0.1684 \n",
      "Epoch 46/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9472 - loss: 0.1228 \n",
      "Epoch 47/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - binary_accuracy: 0.9495 - loss: 0.1389\n",
      "Epoch 48/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step - binary_accuracy: 0.9318 - loss: 0.1640\n",
      "Epoch 49/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979us/step - binary_accuracy: 0.9043 - loss: 0.2071\n",
      "Epoch 50/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9213 - loss: 0.1801 \n",
      "Epoch 51/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - binary_accuracy: 0.9458 - loss: 0.1385\n",
      "Epoch 52/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9456 - loss: 0.1327 \n",
      "Epoch 53/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9215 - loss: 0.1553 \n",
      "Epoch 54/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9324 - loss: 0.1596 \n",
      "Epoch 55/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9407 - loss: 0.1317 \n",
      "Epoch 56/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - binary_accuracy: 0.9436 - loss: 0.1314\n",
      "Epoch 57/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9524 - loss: 0.1543 \n",
      "Epoch 58/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9280 - loss: 0.1596 \n",
      "Epoch 59/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - binary_accuracy: 0.9287 - loss: 0.1736\n",
      "Epoch 60/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - binary_accuracy: 0.9052 - loss: 0.1964\n",
      "Epoch 61/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9227 - loss: 0.1658\n",
      "Epoch 62/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - binary_accuracy: 0.9516 - loss: 0.1096\n",
      "Epoch 63/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - binary_accuracy: 0.9354 - loss: 0.1536\n",
      "Epoch 64/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - binary_accuracy: 0.9479 - loss: 0.1227\n",
      "Epoch 65/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724us/step - binary_accuracy: 0.9649 - loss: 0.1128\n",
      "Epoch 66/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - binary_accuracy: 0.9550 - loss: 0.1335\n",
      "Epoch 67/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - binary_accuracy: 0.9489 - loss: 0.1081\n",
      "Epoch 68/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - binary_accuracy: 0.9509 - loss: 0.1124\n",
      "Epoch 69/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - binary_accuracy: 0.9446 - loss: 0.1351\n",
      "Epoch 70/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 731us/step - binary_accuracy: 0.9530 - loss: 0.1021\n",
      "Epoch 71/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - binary_accuracy: 0.9396 - loss: 0.1126\n",
      "Epoch 72/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - binary_accuracy: 0.9337 - loss: 0.1564\n",
      "Epoch 73/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step - binary_accuracy: 0.9618 - loss: 0.0987\n",
      "Epoch 74/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - binary_accuracy: 0.9332 - loss: 0.1395\n",
      "Epoch 75/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - binary_accuracy: 0.9392 - loss: 0.1407\n",
      "Epoch 76/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777us/step - binary_accuracy: 0.9494 - loss: 0.1226\n",
      "Epoch 77/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - binary_accuracy: 0.9535 - loss: 0.1168\n",
      "Epoch 78/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9335 - loss: 0.1614 \n",
      "Epoch 79/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - binary_accuracy: 0.9572 - loss: 0.1026\n",
      "Epoch 80/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - binary_accuracy: 0.9528 - loss: 0.0980\n",
      "Epoch 81/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - binary_accuracy: 0.9464 - loss: 0.1496\n",
      "Epoch 82/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - binary_accuracy: 0.9312 - loss: 0.1197\n",
      "Epoch 83/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - binary_accuracy: 0.9196 - loss: 0.1709\n",
      "Epoch 84/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9098 - loss: 0.2160 \n",
      "Epoch 85/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - binary_accuracy: 0.8565 - loss: 0.4225\n",
      "Epoch 86/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - binary_accuracy: 0.9238 - loss: 0.1695\n",
      "Epoch 87/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - binary_accuracy: 0.9279 - loss: 0.1721\n",
      "Epoch 88/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - binary_accuracy: 0.9383 - loss: 0.1247\n",
      "Epoch 89/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - binary_accuracy: 0.9595 - loss: 0.1108\n",
      "Epoch 90/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step - binary_accuracy: 0.9490 - loss: 0.1069\n",
      "Epoch 91/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9466 - loss: 0.1274 \n",
      "Epoch 92/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9282 - loss: 0.1537 \n",
      "Epoch 93/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9536 - loss: 0.1149 \n",
      "Epoch 94/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - binary_accuracy: 0.9335 - loss: 0.1398\n",
      "Epoch 95/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - binary_accuracy: 0.9521 - loss: 0.1002\n",
      "Epoch 96/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - binary_accuracy: 0.9600 - loss: 0.1160\n",
      "Epoch 97/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - binary_accuracy: 0.9471 - loss: 0.1376\n",
      "Epoch 98/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - binary_accuracy: 0.9660 - loss: 0.0914\n",
      "Epoch 99/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step - binary_accuracy: 0.9394 - loss: 0.1380\n",
      "Epoch 100/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - binary_accuracy: 0.9315 - loss: 0.1542\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2457dcae330>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classificador.fit(previsores_treinamento, classe_treinamento, batch_size = 10, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-2.72015575e-02,  4.35495153e-02, -1.07422091e-01,\n",
      "         5.54214120e-02, -3.26796740e-01,  1.83851868e-01,\n",
      "         5.47624798e-03,  2.77307685e-02, -3.57036665e-02,\n",
      "         4.72918415e-04, -5.65182418e-04, -2.93477774e-01,\n",
      "         6.69351965e-02, -2.73004383e-01,  3.28595459e-01,\n",
      "         8.48191828e-02],\n",
      "       [-2.97143757e-02, -7.65946519e-04, -1.27418548e-01,\n",
      "         7.31365457e-02, -9.72361267e-02,  5.70498146e-02,\n",
      "        -2.29926668e-02, -2.11352557e-02, -5.82717806e-02,\n",
      "         1.57457739e-02, -3.43625769e-02,  1.67813003e-02,\n",
      "         3.90830338e-02, -2.07683891e-02,  4.46607508e-02,\n",
      "        -5.42574264e-02],\n",
      "       [-2.17741095e-02, -4.45118099e-02, -8.29685256e-02,\n",
      "         2.38268562e-02, -2.70971030e-01,  1.23870820e-01,\n",
      "         1.22992811e-03, -3.08979824e-02, -8.27135295e-02,\n",
      "         6.95844963e-02,  6.09395653e-03, -1.83039084e-01,\n",
      "         6.65065572e-02, -1.98116183e-01,  2.14131340e-01,\n",
      "         1.25688657e-01],\n",
      "       [-4.44062464e-02, -5.36347181e-02,  1.80931110e-02,\n",
      "         7.54938787e-03,  7.41079263e-03,  5.26119769e-02,\n",
      "        -4.86062989e-02,  1.37580195e-02,  4.78550047e-03,\n",
      "         3.71937566e-02, -2.81945113e-02, -8.55030343e-02,\n",
      "         1.19550088e-02, -5.30354045e-02,  2.49442756e-02,\n",
      "         3.67156714e-02],\n",
      "       [-3.17187086e-02, -3.97831425e-02,  2.86477953e-02,\n",
      "         8.87463614e-02,  3.33688036e-02, -1.36586770e-01,\n",
      "        -6.74873739e-02, -5.16243242e-02, -3.39765847e-02,\n",
      "         2.67431010e-02,  3.79333980e-02,  9.25732628e-02,\n",
      "         6.25277013e-02,  1.08368188e-01,  1.22681379e-01,\n",
      "        -2.49697268e-01],\n",
      "       [-9.31857154e-03,  6.79109171e-02, -6.94812089e-02,\n",
      "         3.45387161e-02, -1.78686589e-01, -1.63797274e-01,\n",
      "        -8.02518874e-02,  6.00006199e-03,  4.08913195e-02,\n",
      "        -3.82595509e-02, -1.10495314e-02,  7.61454105e-02,\n",
      "         3.11860383e-01, -1.10987432e-01, -1.25543535e-01,\n",
      "        -1.15213096e-01],\n",
      "       [ 3.77634354e-02,  2.31021177e-02, -4.36856337e-02,\n",
      "        -7.83452019e-02, -1.48519129e-02,  9.94019434e-02,\n",
      "         5.46230152e-02,  7.94204921e-02,  8.94056913e-03,\n",
      "        -2.41255201e-02, -3.17849405e-02,  3.24544869e-02,\n",
      "         1.07908800e-01,  4.71981019e-02, -1.42172530e-01,\n",
      "         1.58046633e-01],\n",
      "       [-4.36511151e-02, -5.27326837e-02,  1.03749514e-01,\n",
      "         1.51253328e-01,  6.36077439e-03,  1.72607508e-02,\n",
      "         7.58012477e-03,  3.65125649e-02, -1.31727345e-02,\n",
      "         1.27815539e-02, -2.71332748e-02,  2.48874482e-02,\n",
      "        -1.87521234e-01,  4.31535356e-02,  1.49162235e-02,\n",
      "         2.43315771e-02],\n",
      "       [ 2.54541133e-02, -2.09800098e-02,  1.36512415e-02,\n",
      "         4.15332392e-02, -2.95105577e-02,  2.84599662e-02,\n",
      "         1.50514141e-01, -5.24408370e-02,  1.93347074e-02,\n",
      "         2.74195839e-02,  3.30860130e-02, -5.23384474e-02,\n",
      "         3.24613720e-01,  2.43823603e-01,  4.74686958e-02,\n",
      "        -2.41791084e-03],\n",
      "       [ 4.31560390e-02,  3.50242890e-02,  2.43627504e-01,\n",
      "         7.18043745e-02,  1.33548424e-01,  3.29068035e-01,\n",
      "        -6.47217631e-02, -3.59237492e-02,  4.43418324e-02,\n",
      "        -4.41766828e-02, -2.31514815e-02, -1.58476934e-01,\n",
      "        -1.42422467e-01, -1.79109350e-01, -6.07425198e-02,\n",
      "         6.49120212e-02],\n",
      "       [-4.67218533e-02,  4.28346591e-03, -6.31256253e-02,\n",
      "         1.04970429e-02,  7.72084668e-02, -1.23341836e-01,\n",
      "        -8.23741928e-02, -4.53096852e-02,  3.57918292e-02,\n",
      "        -1.75908171e-02, -3.84827852e-02, -3.21472771e-02,\n",
      "         9.38996747e-02, -5.60078137e-02,  3.01466621e-02,\n",
      "        -2.69708224e-02],\n",
      "       [ 1.72672626e-02, -6.12512650e-03,  4.13775742e-02,\n",
      "        -3.79000045e-02,  7.53064826e-03, -2.89266203e-02,\n",
      "         6.68739006e-02, -4.10132334e-02,  3.59554752e-03,\n",
      "        -5.84268421e-02, -4.68753688e-02, -1.26992771e-02,\n",
      "         1.18375905e-02,  4.45598597e-03,  1.68850403e-02,\n",
      "        -9.13507566e-02],\n",
      "       [-2.29058526e-02, -3.61077040e-02, -5.60530908e-02,\n",
      "        -6.60866275e-02, -9.70451441e-03, -3.43166804e-03,\n",
      "        -1.10027650e-02,  5.63750323e-03, -1.24655599e-02,\n",
      "        -5.82421049e-02, -4.70902100e-02,  2.67765727e-02,\n",
      "        -3.97560783e-02,  9.04910732e-04,  8.14462197e-04,\n",
      "         2.36385893e-02],\n",
      "       [-6.56613037e-02,  5.71414195e-02,  2.77405418e-03,\n",
      "        -3.62234116e-02,  5.00930287e-02, -1.53090954e-01,\n",
      "        -7.37414733e-02, -7.13987127e-02, -1.89158436e-05,\n",
      "        -1.23961810e-02, -2.52082236e-02,  6.39358861e-03,\n",
      "         3.60965729e-02,  2.41969451e-02,  1.84483675e-03,\n",
      "         5.18417992e-02],\n",
      "       [-5.45522235e-02, -4.37232926e-02, -4.16502297e-01,\n",
      "         8.79185423e-02, -3.35858352e-02,  1.26592666e-01,\n",
      "        -5.47224991e-02, -2.49113068e-02,  8.59695021e-03,\n",
      "         1.30702883e-01, -3.61467600e-02,  5.20081706e-02,\n",
      "        -3.03013399e-02,  5.85526712e-02,  7.77034387e-02,\n",
      "         3.15271243e-02],\n",
      "       [-5.21163642e-02,  4.94187810e-02, -3.45506072e-01,\n",
      "         2.91945692e-02, -2.81090766e-01, -1.44429445e-01,\n",
      "         2.38074869e-01,  2.02542245e-02, -8.45237356e-03,\n",
      "         1.36494219e-01,  2.11787932e-02,  5.72771490e-01,\n",
      "         2.30323508e-01, -8.97384658e-02,  2.88191885e-01,\n",
      "        -5.35203099e-01],\n",
      "       [-4.75819185e-02,  5.42851798e-02,  1.13216341e-01,\n",
      "        -2.30880082e-02,  1.94256261e-01,  7.38343224e-02,\n",
      "        -7.92615414e-02,  4.00498696e-03,  1.81855202e-01,\n",
      "        -2.07642429e-02, -2.73011625e-04,  1.77390590e-01,\n",
      "        -1.57337919e-01,  1.02799453e-01, -5.90903265e-03,\n",
      "        -6.26151189e-02],\n",
      "       [-7.02890530e-02, -8.38349573e-03,  1.09584697e-01,\n",
      "         1.18512444e-01,  3.62743102e-02,  2.45452877e-02,\n",
      "        -4.99482937e-02,  2.06093807e-02, -3.67951170e-02,\n",
      "         1.24582231e-01, -2.63041016e-02,  1.27399936e-01,\n",
      "        -1.77570716e-01, -1.34906545e-02, -3.05439383e-02,\n",
      "        -8.09055641e-02],\n",
      "       [-9.93086398e-03, -5.59070148e-03, -6.54232055e-02,\n",
      "         7.38412291e-02, -1.57500625e-01,  2.85754204e-01,\n",
      "        -4.76825284e-03, -1.36447754e-02, -2.11284142e-02,\n",
      "         2.74132770e-02,  1.54339187e-02, -1.91338688e-01,\n",
      "        -6.10438287e-02, -2.80748308e-01, -7.79997036e-02,\n",
      "         3.11992645e-01],\n",
      "       [-2.38316096e-02, -5.26583269e-02,  2.00678147e-02,\n",
      "         9.14378241e-02,  3.61343265e-01,  1.41094372e-01,\n",
      "        -2.27488965e-01,  1.96159650e-02,  1.72310527e-02,\n",
      "        -4.26774696e-02,  9.87015665e-04,  3.81075680e-01,\n",
      "         1.17838588e-02,  4.10445392e-01, -3.60765964e-01,\n",
      "        -1.13599456e-03],\n",
      "       [-5.25593571e-02,  1.73187237e-02, -8.46300945e-02,\n",
      "         4.17882763e-02, -2.53434509e-01,  1.54526889e-01,\n",
      "        -3.91367227e-02, -1.74933169e-02,  7.89041689e-04,\n",
      "         9.37259570e-02, -8.30293819e-03, -2.02046290e-01,\n",
      "         7.97397196e-02, -1.60220847e-01,  1.70768172e-01,\n",
      "         8.90557542e-02],\n",
      "       [ 2.09811088e-02, -1.18619865e-02, -1.26680106e-01,\n",
      "         4.17462364e-02,  6.47399500e-02, -4.00248654e-02,\n",
      "        -7.88332000e-02, -4.12621200e-02, -2.60846019e-02,\n",
      "         6.93874583e-02, -4.35044430e-02,  1.87549561e-01,\n",
      "        -6.72032461e-02,  9.72262248e-02, -8.92649367e-02,\n",
      "        -1.49046198e-01],\n",
      "       [-4.79965620e-02, -4.64673974e-02, -5.59151843e-02,\n",
      "         6.11837842e-02, -1.68204501e-01,  5.87052777e-02,\n",
      "        -2.18498185e-02, -6.61365092e-02, -1.12799192e-02,\n",
      "         1.56944804e-02, -3.88451591e-02, -1.19548403e-01,\n",
      "         7.94108491e-03, -1.33744240e-01,  1.91585869e-01,\n",
      "         4.53292243e-02],\n",
      "       [-3.52079980e-02, -1.59361437e-02, -3.89829054e-02,\n",
      "        -4.19126675e-02,  1.02547541e-01, -9.35839862e-02,\n",
      "        -1.16209976e-01, -7.10072666e-02, -5.91134802e-02,\n",
      "         1.57575849e-02, -3.46529596e-02,  7.91658983e-02,\n",
      "        -1.01509737e-02,  9.69267190e-02, -6.03367910e-02,\n",
      "        -6.81825355e-02],\n",
      "       [ 2.50387993e-02,  9.65845399e-03,  3.93401310e-02,\n",
      "         5.42998910e-02,  3.47635746e-02,  6.49980083e-02,\n",
      "         1.05124094e-01,  4.82081342e-03,  4.38724793e-02,\n",
      "         1.55515748e-03,  3.94206159e-02, -1.28410727e-01,\n",
      "        -2.32006133e-01, -8.00380297e-03, -1.08243555e-01,\n",
      "        -1.40694780e-02],\n",
      "       [ 3.18393819e-02,  7.93237239e-03, -1.17846243e-01,\n",
      "         4.44013216e-02, -4.40282375e-02,  3.12586762e-02,\n",
      "        -4.35695006e-03, -8.87380727e-03, -7.92104378e-02,\n",
      "        -5.23025403e-03, -4.81945649e-02, -7.61727393e-02,\n",
      "         1.42414182e-01,  4.33060490e-02, -1.81714818e-02,\n",
      "        -3.55158858e-02],\n",
      "       [ 7.63371726e-03,  5.95106445e-02, -1.02308348e-01,\n",
      "         5.65759055e-02, -2.78460551e-02, -2.67883344e-03,\n",
      "        -2.25112550e-02,  1.97809152e-02, -4.31967750e-02,\n",
      "         6.52364194e-02,  9.72163677e-03, -1.06398314e-01,\n",
      "         3.45987156e-02,  8.94829538e-03, -4.94669080e-02,\n",
      "        -3.79941575e-02],\n",
      "       [-4.37922068e-02,  6.25792472e-03, -9.41723585e-02,\n",
      "         1.21793486e-02, -9.32455435e-02, -3.51167545e-02,\n",
      "         5.90577014e-02, -8.58129654e-03, -3.45600583e-02,\n",
      "        -2.19945405e-02,  8.87516886e-03, -6.88904002e-02,\n",
      "         3.48688543e-01,  1.46107338e-02, -6.22054785e-02,\n",
      "        -5.00194505e-02],\n",
      "       [-2.37648766e-02, -3.39972749e-02, -5.79395406e-02,\n",
      "         9.89260152e-03, -2.95205377e-02, -7.12785274e-02,\n",
      "        -4.43875082e-02,  3.71719301e-02, -6.65581003e-02,\n",
      "        -8.03780034e-02, -2.65317317e-02, -1.35872886e-02,\n",
      "         2.18177214e-01,  7.36803785e-02, -5.81876263e-02,\n",
      "         5.75888306e-02],\n",
      "       [ 1.28413131e-03,  5.47085889e-04,  3.17643397e-02,\n",
      "         5.87820821e-02,  3.14249516e-01, -6.99449629e-02,\n",
      "        -8.68216902e-02, -5.06914174e-03,  4.37477343e-02,\n",
      "         2.78453939e-02,  4.76774611e-02,  2.04479113e-01,\n",
      "        -1.16324611e-01,  2.79893696e-01, -2.14130536e-01,\n",
      "        -6.15130961e-02]], dtype=float32), array([-2.0797836e-02, -8.0489854e-06, -1.8277244e-01,  9.4907925e-02,\n",
      "       -5.0174433e-01,  3.0219981e-01,  4.4350456e-02, -1.6451932e-02,\n",
      "       -3.9904717e-02,  1.2172677e-01,  0.0000000e+00, -4.3291014e-01,\n",
      "        1.7408508e-01, -4.7594941e-01,  4.8180085e-01,  2.3992927e-01],\n",
      "      dtype=float32)]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "pesos0 = classificador.layers[0].get_weights()\n",
    "print(pesos0)\n",
    "print(len(pesos0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n"
     ]
    }
   ],
   "source": [
    "previsoes = classificador.predict(previsores_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.8794 - loss: 0.4326  \n"
     ]
    }
   ],
   "source": [
    "resultado = classificador.evaluate(previsores_teste, classe_teste)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
