{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #importando nossa biblioteca Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsores = pd.read_csv('entradas_breast.csv') #declarando nossas variáveis de entrada\n",
    "classe = pd.read_csv('saidas_breast.csv') #declarando nossas variáveis de saida (expectativa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split #Criando os ambientes de treinamento e teste\n",
    "previsores_treinamento, previsores_teste, classe_treinamento, classe_teste = train_test_split(previsores, classe, test_size=0.25) #Declarando as variáveis de treinamento e de teste, em seguida splitando elas através do train_test_slipt, usando test_size = 25, indica que estamos utilizando apenas 25% de todos os registros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samue\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import keras #importando o Keras\n",
    "from keras.models import Sequential #Sequential é a modelo q vamos usar, possui esse nome pois é aformado pela sequência (entrada, primeira camada oculta, segunda camada oculta e saida)\n",
    "from keras.layers import Dense #Dense é o modelo de rede neural densa ou fully connected\n",
    "classificador = Sequential() #nossa rede neural se chama Sequential \n",
    "classificador.add(Dense(units=16, activation='relu', kernel_initializer='random_uniform', input_dim=30)) #Criando nossa primeira camada oculta. Units = Qtde de neuronios de entrada formula (qtde de entradas = 30 + qtde de saidas = 1) e divide por 2. O primeiro activation utilizamos o relu. Initializer é método pelo qual ele vai selecionar as entradas por isso utlizamos random. Input_dim é a qtde de elementos na camada de entrada do programa.\n",
    "classificador.add(Dense(units=16, activation='relu', kernel_initializer='random_uniform')) \n",
    "classificador.add(Dense(units=1, activation='sigmoid')) #Criando nossa camada de saida, units é a qtde de neurônios de saida e actvation nossa função de ativação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#otimizador = keras.optimizers.Adam(learning_rate = 0.001, weight_decay = 0.0001, clipvalue = 0.5)\n",
    "#classificador.compile(optimizer = otimizador, loss = 'binary_crossentropy', metrics= ['binary_accuracy'])\n",
    "classificador.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics= ['binary_accuracy']) #utilizando o otimizador ADAM para fazer o ajuste dos pesos (realiza a otimização da descida do gradiente stocastico). Loss binary crossentropy utilizamos essa função quando trabalhamos apenas com duas classes. Metrics= binary_accuracy para testar a acuracidade da nossa saida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - binary_accuracy: 0.5083 - loss: 1.7350\n",
      "Epoch 2/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.7326 - loss: 0.4750 \n",
      "Epoch 3/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.7846 - loss: 0.4198 \n",
      "Epoch 4/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.8333 - loss: 0.3808 \n",
      "Epoch 5/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - binary_accuracy: 0.8165 - loss: 0.3951\n",
      "Epoch 6/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.8518 - loss: 0.3409 \n",
      "Epoch 7/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9006 - loss: 0.2684 \n",
      "Epoch 8/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.8256 - loss: 0.3815 \n",
      "Epoch 9/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9009 - loss: 0.3118 \n",
      "Epoch 10/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - binary_accuracy: 0.8673 - loss: 0.3190\n",
      "Epoch 11/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - binary_accuracy: 0.8450 - loss: 0.3261\n",
      "Epoch 12/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - binary_accuracy: 0.9147 - loss: 0.2594\n",
      "Epoch 13/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - binary_accuracy: 0.8971 - loss: 0.2440\n",
      "Epoch 14/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - binary_accuracy: 0.9008 - loss: 0.2539\n",
      "Epoch 15/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - binary_accuracy: 0.9061 - loss: 0.2300\n",
      "Epoch 16/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - binary_accuracy: 0.9053 - loss: 0.2123\n",
      "Epoch 17/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - binary_accuracy: 0.8926 - loss: 0.2530\n",
      "Epoch 18/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - binary_accuracy: 0.8742 - loss: 0.3041\n",
      "Epoch 19/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864us/step - binary_accuracy: 0.8961 - loss: 0.2537\n",
      "Epoch 20/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9026 - loss: 0.2481\n",
      "Epoch 21/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - binary_accuracy: 0.8976 - loss: 0.2545\n",
      "Epoch 22/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - binary_accuracy: 0.9087 - loss: 0.2030\n",
      "Epoch 23/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - binary_accuracy: 0.8641 - loss: 0.2856\n",
      "Epoch 24/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - binary_accuracy: 0.9280 - loss: 0.2001\n",
      "Epoch 25/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - binary_accuracy: 0.9054 - loss: 0.2043\n",
      "Epoch 26/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.8947 - loss: 0.2528\n",
      "Epoch 27/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - binary_accuracy: 0.9462 - loss: 0.1909\n",
      "Epoch 28/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step - binary_accuracy: 0.9020 - loss: 0.2158\n",
      "Epoch 29/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step - binary_accuracy: 0.8928 - loss: 0.2349\n",
      "Epoch 30/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - binary_accuracy: 0.9379 - loss: 0.1683\n",
      "Epoch 31/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777us/step - binary_accuracy: 0.9176 - loss: 0.1793\n",
      "Epoch 32/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.8752 - loss: 0.2243 \n",
      "Epoch 33/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - binary_accuracy: 0.9047 - loss: 0.2103\n",
      "Epoch 34/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - binary_accuracy: 0.9211 - loss: 0.2091\n",
      "Epoch 35/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - binary_accuracy: 0.9367 - loss: 0.1966\n",
      "Epoch 36/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - binary_accuracy: 0.9283 - loss: 0.1991\n",
      "Epoch 37/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - binary_accuracy: 0.9027 - loss: 0.2151\n",
      "Epoch 38/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - binary_accuracy: 0.9366 - loss: 0.1718\n",
      "Epoch 39/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - binary_accuracy: 0.9024 - loss: 0.2204\n",
      "Epoch 40/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - binary_accuracy: 0.9456 - loss: 0.1661\n",
      "Epoch 41/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - binary_accuracy: 0.9325 - loss: 0.1793\n",
      "Epoch 42/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - binary_accuracy: 0.9189 - loss: 0.1858\n",
      "Epoch 43/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - binary_accuracy: 0.9022 - loss: 0.2171\n",
      "Epoch 44/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - binary_accuracy: 0.9465 - loss: 0.1425\n",
      "Epoch 45/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - binary_accuracy: 0.9256 - loss: 0.1748\n",
      "Epoch 46/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - binary_accuracy: 0.9355 - loss: 0.1553\n",
      "Epoch 47/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - binary_accuracy: 0.9610 - loss: 0.1135\n",
      "Epoch 48/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9280 - loss: 0.1736\n",
      "Epoch 49/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9109 - loss: 0.2557 \n",
      "Epoch 50/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - binary_accuracy: 0.9031 - loss: 0.2312\n",
      "Epoch 51/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step - binary_accuracy: 0.9357 - loss: 0.1784\n",
      "Epoch 52/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - binary_accuracy: 0.9133 - loss: 0.1688\n",
      "Epoch 53/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - binary_accuracy: 0.9273 - loss: 0.1728\n",
      "Epoch 54/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - binary_accuracy: 0.9241 - loss: 0.1834\n",
      "Epoch 55/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - binary_accuracy: 0.9273 - loss: 0.1620\n",
      "Epoch 56/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - binary_accuracy: 0.9382 - loss: 0.1373\n",
      "Epoch 57/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - binary_accuracy: 0.9354 - loss: 0.1667\n",
      "Epoch 58/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9257 - loss: 0.1758 \n",
      "Epoch 59/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9593 - loss: 0.1281 \n",
      "Epoch 60/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9460 - loss: 0.1402 \n",
      "Epoch 61/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9472 - loss: 0.1396 \n",
      "Epoch 62/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9351 - loss: 0.1551 \n",
      "Epoch 63/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9323 - loss: 0.1519 \n",
      "Epoch 64/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9333 - loss: 0.1772 \n",
      "Epoch 65/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9308 - loss: 0.1690 \n",
      "Epoch 66/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9412 - loss: 0.1433 \n",
      "Epoch 67/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - binary_accuracy: 0.9517 - loss: 0.1251\n",
      "Epoch 68/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9264 - loss: 0.1670 \n",
      "Epoch 69/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9602 - loss: 0.1199 \n",
      "Epoch 70/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9543 - loss: 0.1183 \n",
      "Epoch 71/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9552 - loss: 0.1303 \n",
      "Epoch 72/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9190 - loss: 0.2013 \n",
      "Epoch 73/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9521 - loss: 0.1197 \n",
      "Epoch 74/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9402 - loss: 0.1298 \n",
      "Epoch 75/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9483 - loss: 0.1456 \n",
      "Epoch 76/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9222 - loss: 0.1682 \n",
      "Epoch 77/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9394 - loss: 0.1134 \n",
      "Epoch 78/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9383 - loss: 0.1366 \n",
      "Epoch 79/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9214 - loss: 0.1599 \n",
      "Epoch 80/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9416 - loss: 0.1586 \n",
      "Epoch 81/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9185 - loss: 0.1697 \n",
      "Epoch 82/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9408 - loss: 0.1516 \n",
      "Epoch 83/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - binary_accuracy: 0.8827 - loss: 0.2228\n",
      "Epoch 84/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - binary_accuracy: 0.9382 - loss: 0.1523\n",
      "Epoch 85/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - binary_accuracy: 0.9361 - loss: 0.1667\n",
      "Epoch 86/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - binary_accuracy: 0.9247 - loss: 0.1583\n",
      "Epoch 87/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - binary_accuracy: 0.9566 - loss: 0.1205\n",
      "Epoch 88/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - binary_accuracy: 0.9501 - loss: 0.1516\n",
      "Epoch 89/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - binary_accuracy: 0.9273 - loss: 0.1316\n",
      "Epoch 90/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - binary_accuracy: 0.9422 - loss: 0.1263\n",
      "Epoch 91/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step - binary_accuracy: 0.9371 - loss: 0.1333\n",
      "Epoch 92/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - binary_accuracy: 0.9436 - loss: 0.1402\n",
      "Epoch 93/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - binary_accuracy: 0.9430 - loss: 0.1519\n",
      "Epoch 94/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - binary_accuracy: 0.9329 - loss: 0.1411\n",
      "Epoch 95/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - binary_accuracy: 0.9338 - loss: 0.1428\n",
      "Epoch 96/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - binary_accuracy: 0.9351 - loss: 0.1785\n",
      "Epoch 97/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - binary_accuracy: 0.9332 - loss: 0.1374\n",
      "Epoch 98/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - binary_accuracy: 0.9213 - loss: 0.1617\n",
      "Epoch 99/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - binary_accuracy: 0.9489 - loss: 0.1341\n",
      "Epoch 100/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - binary_accuracy: 0.9356 - loss: 0.1228\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x20f7d8fe5a0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classificador.fit(previsores_treinamento, classe_treinamento, batch_size = 10, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-2.42585152e-01,  5.63122779e-02, -2.74535060e-01,\n",
      "        -4.00803890e-03,  2.96625476e-02,  8.93772114e-03,\n",
      "         2.72443127e-02,  2.01553591e-02,  5.68988509e-02,\n",
      "         1.08017381e-02,  7.90469069e-03, -2.67456234e-01,\n",
      "        -6.38786852e-02,  4.20122320e-04,  1.40821571e-02,\n",
      "         4.77826893e-02],\n",
      "       [ 8.63112286e-02, -3.37210819e-02,  8.53820983e-03,\n",
      "         1.62077986e-03, -4.96660098e-02,  2.93923020e-02,\n",
      "         6.05737604e-02, -4.92823310e-02, -4.12616618e-02,\n",
      "        -4.07476462e-02,  3.11278030e-02, -8.18120316e-02,\n",
      "        -9.14584845e-02,  1.77167848e-01, -2.82132387e-01,\n",
      "         5.10999896e-02],\n",
      "       [-2.24380836e-01, -5.40312715e-02, -2.13961065e-01,\n",
      "         1.50306094e-02, -2.54066307e-02,  1.21499263e-01,\n",
      "         1.61361739e-01, -2.14695588e-01, -3.74506973e-02,\n",
      "         3.89081314e-02, -7.34538259e-03, -1.97144568e-01,\n",
      "        -6.28776997e-02,  9.96810794e-02, -7.42803961e-02,\n",
      "         2.96867728e-01],\n",
      "       [-4.98772599e-02, -2.36569159e-02, -5.16724922e-02,\n",
      "        -8.15285742e-02, -5.72412014e-02,  5.04887663e-02,\n",
      "         2.81289443e-02, -3.97976413e-02,  8.94549582e-03,\n",
      "        -2.27547307e-02, -9.74724442e-03,  4.40930715e-03,\n",
      "        -4.31926623e-02, -3.33517678e-02,  4.94114310e-02,\n",
      "         7.45289996e-02],\n",
      "       [ 1.94305047e-01,  3.94663066e-02,  7.47795776e-02,\n",
      "         6.90626502e-02,  1.68495566e-01, -1.22292913e-01,\n",
      "         4.09986451e-02, -5.68518639e-02,  1.24312818e-01,\n",
      "        -6.50007278e-03,  1.36504220e-02, -3.10478248e-02,\n",
      "        -8.44802558e-02, -3.92533056e-02,  2.78065372e-02,\n",
      "        -5.35418466e-02],\n",
      "       [-1.60631925e-01,  1.64491823e-04, -3.03360760e-01,\n",
      "         1.10810371e-02,  4.52128947e-01, -1.51462317e-01,\n",
      "        -1.67649597e-01,  5.23636602e-02,  1.50093110e-02,\n",
      "         2.46785730e-02, -2.07283869e-02,  9.80805084e-02,\n",
      "         1.36253552e-03, -8.89619812e-02,  1.36742622e-01,\n",
      "        -3.55673172e-02],\n",
      "       [-7.73705840e-02,  2.63645407e-02,  1.71899021e-01,\n",
      "        -4.02934216e-02,  6.80944622e-02, -5.02711609e-02,\n",
      "        -1.17244884e-01,  6.91120513e-03,  3.44377793e-02,\n",
      "         2.53307223e-02, -4.51156572e-02,  3.92451277e-03,\n",
      "         2.97007971e-02,  1.04301572e-02,  1.83033627e-02,\n",
      "        -3.11491787e-02],\n",
      "       [ 3.13082300e-02,  3.05839777e-02, -4.70737368e-02,\n",
      "         9.19294208e-02,  4.50833231e-01, -6.46235123e-02,\n",
      "         1.61528125e-01, -1.68297186e-01, -3.51885408e-02,\n",
      "         2.15161853e-02, -6.74729049e-02, -1.63231656e-01,\n",
      "        -8.56732111e-03, -7.71628842e-02, -3.82827312e-01,\n",
      "         4.66427393e-02],\n",
      "       [ 9.40438509e-02, -7.83086196e-03, -6.79558069e-02,\n",
      "        -1.99917741e-02,  1.22416161e-01, -5.28584532e-02,\n",
      "         8.43734965e-02, -1.57616049e-01,  3.20718102e-02,\n",
      "         1.85629854e-03, -2.68888520e-03, -2.95243226e-02,\n",
      "        -2.80657578e-02,  1.98210225e-01, -1.88728333e-01,\n",
      "         2.48101652e-02],\n",
      "       [ 3.16175297e-02, -2.34852750e-02, -3.87720317e-01,\n",
      "        -2.83347875e-01,  2.66392250e-02,  1.05916932e-01,\n",
      "        -1.14391886e-01, -3.45834255e-01,  1.26893129e-02,\n",
      "         8.48782435e-03, -1.34767801e-01, -5.50345853e-02,\n",
      "         1.33794453e-02, -1.86762199e-01,  1.43735021e-01,\n",
      "         3.57742086e-02],\n",
      "       [ 5.75670041e-02, -3.44521627e-02, -1.13899983e-01,\n",
      "        -6.90279761e-03, -3.37607302e-02, -6.27398118e-02,\n",
      "        -1.48058265e-01,  2.29098331e-02,  3.50800157e-02,\n",
      "        -3.44965197e-02, -2.10380200e-02,  3.67100127e-02,\n",
      "         2.07404122e-02, -4.83143665e-02,  2.72371452e-02,\n",
      "         2.18887273e-02],\n",
      "       [ 3.64639387e-02, -2.23054015e-03, -1.65994726e-02,\n",
      "         4.27935049e-02,  2.61016097e-02, -6.24732785e-02,\n",
      "         3.30538936e-02, -1.74540598e-02, -3.96771580e-02,\n",
      "        -3.55531536e-02, -4.95405402e-04,  4.85642673e-03,\n",
      "         8.95549194e-04, -2.67822156e-03,  1.43187018e-02,\n",
      "         7.65652815e-03],\n",
      "       [-1.71945374e-02, -1.45338271e-02,  2.56284308e-02,\n",
      "        -2.40640417e-02,  3.77587155e-02,  1.90530308e-02,\n",
      "         1.11741712e-02,  1.83687974e-02, -3.19256000e-02,\n",
      "        -1.30805075e-02, -8.34436156e-03,  3.84060177e-03,\n",
      "        -3.06884684e-02, -5.17512560e-02, -8.21925998e-02,\n",
      "        -4.30619996e-03],\n",
      "       [ 1.17363691e-01,  4.81305979e-02,  4.55552004e-02,\n",
      "        -2.08509490e-01,  2.02519316e-02, -1.87448516e-01,\n",
      "        -6.30442277e-02,  1.89093165e-02, -1.67630017e-02,\n",
      "        -3.91269997e-02,  3.92717011e-02,  1.44499596e-02,\n",
      "         8.67340341e-02, -1.19444318e-01,  7.12383911e-03,\n",
      "        -1.19850956e-01],\n",
      "       [ 7.88739398e-02, -3.21908556e-02,  2.00127795e-01,\n",
      "         1.04034953e-01, -6.30986020e-02, -8.53469409e-03,\n",
      "        -6.27945513e-02,  3.43032666e-02,  4.13755476e-02,\n",
      "         4.08327719e-03,  7.54621550e-02, -3.12736747e-03,\n",
      "        -7.17997923e-02,  3.29150379e-01, -2.29492262e-01,\n",
      "        -7.82237351e-02],\n",
      "       [-6.36425018e-02,  8.50511156e-03,  2.25064903e-01,\n",
      "         4.58299756e-01,  8.94030929e-02, -5.04794531e-02,\n",
      "         3.43106776e-01, -8.79480317e-02,  1.66452173e-02,\n",
      "        -3.24406624e-02,  1.72949329e-01, -2.70377755e-01,\n",
      "        -1.20216452e-01,  2.71997333e-01, -3.34081322e-01,\n",
      "         3.85469347e-01],\n",
      "       [-1.69931147e-02,  1.26843629e-02, -2.70230591e-01,\n",
      "        -3.56025100e-02,  7.74083361e-02, -4.65341061e-02,\n",
      "         1.50300577e-01, -2.08305731e-01,  3.53976749e-02,\n",
      "         1.39216650e-02, -1.69520099e-02, -1.31701976e-01,\n",
      "        -2.84252539e-02, -1.28603101e-01,  1.09563261e-01,\n",
      "         3.01584333e-01],\n",
      "       [-4.83548075e-01,  2.47279201e-02, -3.12427074e-01,\n",
      "        -5.17071597e-02,  1.31142497e-01,  2.95615792e-01,\n",
      "         2.99778074e-01, -3.08619589e-01, -6.02978235e-03,\n",
      "         1.25702480e-02,  1.04797725e-02, -3.23629081e-01,\n",
      "        -3.64073776e-02,  1.03273250e-01, -2.37538621e-01,\n",
      "         4.69467312e-01],\n",
      "       [-4.27548856e-01, -4.64415811e-02, -3.41738164e-01,\n",
      "         7.68182278e-02, -9.93927419e-02,  2.95509219e-01,\n",
      "         3.34455073e-01, -3.41216683e-01,  1.65983029e-02,\n",
      "        -3.39134410e-02,  2.31479388e-02, -2.47234777e-01,\n",
      "        -3.38581242e-02,  1.12120926e-01,  4.81411628e-03,\n",
      "         4.23714221e-01],\n",
      "       [ 5.02755702e-01,  2.01698821e-02,  3.00545245e-01,\n",
      "        -2.98043098e-02, -3.36853683e-01, -2.92813361e-01,\n",
      "        -3.65012765e-01,  3.48476291e-01, -2.91020814e-02,\n",
      "        -4.27183956e-02, -3.38693149e-02,  4.04634714e-01,\n",
      "         3.00866812e-02, -6.01386428e-02,  2.88605988e-01,\n",
      "        -3.98320258e-01],\n",
      "       [-2.12579325e-01, -4.22813110e-02, -2.39661664e-01,\n",
      "        -1.29417386e-02,  7.28921732e-03,  3.25553343e-02,\n",
      "         2.80523505e-02,  4.87933867e-03,  1.80761516e-02,\n",
      "         2.47973502e-02, -2.80848565e-03, -7.55526200e-02,\n",
      "        -4.63128947e-02,  3.91429141e-02,  3.01963985e-02,\n",
      "         6.72159493e-02],\n",
      "       [ 1.93012521e-01,  3.50613333e-02,  1.08647093e-01,\n",
      "         3.22443433e-02, -1.86890766e-01, -8.94707292e-02,\n",
      "        -3.24064121e-02,  9.36151966e-02,  4.13743481e-02,\n",
      "         5.94666367e-03,  2.96267923e-02,  9.01092812e-02,\n",
      "        -7.33276382e-02,  1.40901461e-01, -2.71547914e-01,\n",
      "        -7.37521648e-02],\n",
      "       [-6.85735196e-02,  2.47105658e-02, -6.58222064e-02,\n",
      "         2.90550683e-02, -7.30446652e-02,  1.26363412e-01,\n",
      "         1.40113235e-01, -1.45277843e-01,  2.21570749e-02,\n",
      "         1.06287338e-02, -9.58451722e-03, -1.87836349e-01,\n",
      "        -4.30824459e-02,  8.17107037e-02, -8.99716318e-02,\n",
      "         1.95351675e-01],\n",
      "       [ 1.24163561e-01,  1.53716858e-02,  7.79688060e-02,\n",
      "        -6.14483654e-02, -1.42903835e-01, -3.41112576e-02,\n",
      "        -9.17530581e-02,  8.11564997e-02, -3.02697718e-02,\n",
      "        -3.82926278e-02, -2.16292627e-02,  5.34567572e-02,\n",
      "        -4.78058457e-02, -1.14325732e-02,  6.36980236e-02,\n",
      "        -7.58245736e-02],\n",
      "       [-6.67238310e-02,  3.39120440e-02,  2.08355740e-01,\n",
      "        -1.80280544e-02, -1.46093935e-01,  6.96537122e-02,\n",
      "         7.66124669e-03,  9.00659189e-02,  1.71491746e-02,\n",
      "        -8.84921104e-03, -4.51431610e-02,  5.91803938e-02,\n",
      "        -5.46888821e-03, -3.57665792e-02, -3.22194844e-02,\n",
      "        -1.23338010e-02],\n",
      "       [ 2.82994527e-02,  3.68681289e-02, -1.72112044e-02,\n",
      "        -1.11996606e-02,  1.76988125e-01,  1.69850569e-02,\n",
      "         5.37717994e-03, -1.63585972e-02,  4.22520265e-02,\n",
      "        -9.25981253e-03,  1.02071594e-02,  1.93988848e-02,\n",
      "        -5.94586022e-02,  1.31075382e-01, -8.62235129e-02,\n",
      "         1.30766993e-02],\n",
      "       [ 6.08531851e-03, -3.49158328e-03,  4.32447046e-02,\n",
      "        -5.17313927e-02,  4.20751087e-02,  5.48252789e-03,\n",
      "         1.70969255e-02, -1.89578950e-01,  4.09200750e-02,\n",
      "        -4.06385493e-03, -2.31882581e-03,  6.04388420e-04,\n",
      "        -7.84018543e-03, -8.49426836e-02, -1.73158094e-01,\n",
      "        -2.58722007e-02],\n",
      "       [ 8.80999491e-02, -1.21024959e-02, -7.27233440e-02,\n",
      "         6.95278272e-02,  8.13929141e-02, -1.21218398e-01,\n",
      "        -9.13518891e-02, -1.44808188e-01,  9.43923071e-02,\n",
      "        -3.78183685e-02, -2.57969573e-02,  9.71167609e-02,\n",
      "        -4.06946726e-02,  8.22689533e-02, -1.41340882e-01,\n",
      "        -4.14271690e-02],\n",
      "       [-1.38539687e-01, -3.82929742e-02,  1.37796909e-01,\n",
      "         1.72540173e-01,  2.85632402e-01,  3.38243842e-02,\n",
      "        -1.24299921e-01, -3.99285555e-02,  2.29297392e-02,\n",
      "        -4.25037332e-02,  6.68280944e-02, -8.29009060e-03,\n",
      "        -5.68323284e-02,  8.64336491e-02,  2.63610575e-02,\n",
      "        -2.23712064e-03],\n",
      "       [ 3.20766985e-01, -4.25026268e-02,  2.89685696e-01,\n",
      "        -1.27171516e-01,  5.19918278e-02, -7.32991099e-02,\n",
      "        -2.14980394e-01,  2.51247942e-01, -4.69414284e-03,\n",
      "         1.95148513e-02, -9.59674194e-02,  1.88811749e-01,\n",
      "        -4.24333438e-02,  3.61576341e-02, -4.11514379e-02,\n",
      "        -2.57333279e-01]], dtype=float32), array([-0.41393432,  0.00212508, -0.42379624,  0.07718271,  0.04979215,\n",
      "        0.343597  ,  0.4520797 , -0.466329  ,  0.00877577, -0.00927201,\n",
      "        0.08422607, -0.44483206, -0.04807471,  0.17960064, -0.31184813,\n",
      "        0.5696265 ], dtype=float32)]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "pesos0 = classificador.layers[0].get_weights()\n",
    "print(pesos0)\n",
    "print(len(pesos0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n"
     ]
    }
   ],
   "source": [
    "previsoes = classificador.predict(previsores_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9202 - loss: 0.2712  \n"
     ]
    }
   ],
   "source": [
    "resultado = classificador.evaluate(previsores_teste, classe_teste)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
