{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #importando nossa biblioteca Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsores = pd.read_csv('entradas_breast.csv') #declarando nossas variáveis de entrada\n",
    "classe = pd.read_csv('saidas_breast.csv') #declarando nossas variáveis de saida (expectativa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split #Criando os ambientes de treinamento e teste\n",
    "previsores_treinamento, previsores_teste, classe_treinamento, classe_teste = train_test_split(previsores, classe, test_size=0.25) #Declarando as variáveis de treinamento e de teste, em seguida splitando elas através do train_test_slipt, usando test_size = 25, indica que estamos utilizando apenas 25% de todos os registros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samue\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import keras #importando o Keras\n",
    "from keras.models import Sequential #Sequential é a modelo q vamos usar, possui esse nome pois é aformado pela sequência (entrada, primeira camada oculta, segunda camada oculta e saida)\n",
    "from keras.layers import Dense #Dense é o modelo de rede neural densa ou fully connected\n",
    "classificador = Sequential() #nossa rede neural se chama Sequential \n",
    "classificador.add(Dense(units=16, activation='relu', kernel_initializer='random_uniform', input_dim=30)) #Criando nossa primeira camada oculta. Units = Qtde de neuronios de entrada formula (qtde de entradas = 30 + qtde de saidas = 1) e divide por 2. O primeiro activation utilizamos o relu. Initializer é método pelo qual ele vai selecionar as entradas por isso utlizamos random. Input_dim é a qtde de elementos na camada de entrada do programa.\n",
    "classificador.add(Dense(units=16, activation='relu', kernel_initializer='random_uniform')) \n",
    "classificador.add(Dense(units=1, activation='sigmoid')) #Criando nossa camada de saida, units é a qtde de neurônios de saida e actvation nossa função de ativação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#otimizador = keras.optimizers.Adam(learning_rate = 0.001, weight_decay = 0.0001, clipvalue = 0.5)\n",
    "#classificador.compile(optimizer = otimizador, loss = 'binary_crossentropy', metrics= ['binary_accuracy'])\n",
    "classificador.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics= ['binary_accuracy']) #utilizando o otimizador ADAM para fazer o ajuste dos pesos (realiza a otimização da descida do gradiente stocastico). Loss binary crossentropy utilizamos essa função quando trabalhamos apenas com duas classes. Metrics= binary_accuracy para testar a acuracidade da nossa saida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - binary_accuracy: 0.6159 - loss: 1.1094\n",
      "Epoch 2/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - binary_accuracy: 0.6746 - loss: 0.5440\n",
      "Epoch 3/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.6934 - loss: 0.4816\n",
      "Epoch 4/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.7801 - loss: 0.4242\n",
      "Epoch 5/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.7523 - loss: 0.4715\n",
      "Epoch 6/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 0.8063 - loss: 0.3882\n",
      "Epoch 7/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - binary_accuracy: 0.8332 - loss: 0.3981\n",
      "Epoch 8/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - binary_accuracy: 0.8244 - loss: 0.3538\n",
      "Epoch 9/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 0.8612 - loss: 0.3172\n",
      "Epoch 10/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - binary_accuracy: 0.8587 - loss: 0.3185\n",
      "Epoch 11/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.8465 - loss: 0.3545\n",
      "Epoch 12/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9150 - loss: 0.2517\n",
      "Epoch 13/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9318 - loss: 0.2340\n",
      "Epoch 14/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9222 - loss: 0.2072\n",
      "Epoch 15/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.8863 - loss: 0.2098\n",
      "Epoch 16/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9312 - loss: 0.1846\n",
      "Epoch 17/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.8979 - loss: 0.2281\n",
      "Epoch 18/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9058 - loss: 0.2047\n",
      "Epoch 19/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.8903 - loss: 0.2582\n",
      "Epoch 20/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9236 - loss: 0.1934\n",
      "Epoch 21/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9454 - loss: 0.1624\n",
      "Epoch 22/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9132 - loss: 0.1965\n",
      "Epoch 23/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9265 - loss: 0.2155\n",
      "Epoch 24/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9413 - loss: 0.1801\n",
      "Epoch 25/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9613 - loss: 0.1327\n",
      "Epoch 26/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9395 - loss: 0.1680\n",
      "Epoch 27/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9377 - loss: 0.1483\n",
      "Epoch 28/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9138 - loss: 0.2015 \n",
      "Epoch 29/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9293 - loss: 0.1789\n",
      "Epoch 30/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9275 - loss: 0.1936\n",
      "Epoch 31/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9435 - loss: 0.1774\n",
      "Epoch 32/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9263 - loss: 0.2149\n",
      "Epoch 33/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9439 - loss: 0.1459\n",
      "Epoch 34/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9268 - loss: 0.1933\n",
      "Epoch 35/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9155 - loss: 0.1700\n",
      "Epoch 36/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9568 - loss: 0.1184\n",
      "Epoch 37/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9380 - loss: 0.1653\n",
      "Epoch 38/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9397 - loss: 0.1508\n",
      "Epoch 39/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9145 - loss: 0.2009\n",
      "Epoch 40/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9500 - loss: 0.1514\n",
      "Epoch 41/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9273 - loss: 0.1929\n",
      "Epoch 42/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9602 - loss: 0.1342\n",
      "Epoch 43/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 0.9514 - loss: 0.1369\n",
      "Epoch 44/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - binary_accuracy: 0.9551 - loss: 0.1272\n",
      "Epoch 45/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9648 - loss: 0.1101\n",
      "Epoch 46/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9380 - loss: 0.1749\n",
      "Epoch 47/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9623 - loss: 0.0992\n",
      "Epoch 48/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - binary_accuracy: 0.9445 - loss: 0.1424\n",
      "Epoch 49/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - binary_accuracy: 0.9280 - loss: 0.1615\n",
      "Epoch 50/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9664 - loss: 0.1104\n",
      "Epoch 51/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9618 - loss: 0.0937\n",
      "Epoch 52/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9636 - loss: 0.1335\n",
      "Epoch 53/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9438 - loss: 0.1062\n",
      "Epoch 54/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.9490 - loss: 0.1279\n",
      "Epoch 55/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9548 - loss: 0.1156\n",
      "Epoch 56/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9635 - loss: 0.1075\n",
      "Epoch 57/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9593 - loss: 0.1118\n",
      "Epoch 58/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9579 - loss: 0.1234\n",
      "Epoch 59/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9011 - loss: 0.2614\n",
      "Epoch 60/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9720 - loss: 0.1207\n",
      "Epoch 61/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9370 - loss: 0.1344\n",
      "Epoch 62/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9568 - loss: 0.1149\n",
      "Epoch 63/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9398 - loss: 0.1322\n",
      "Epoch 64/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9529 - loss: 0.1068\n",
      "Epoch 65/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9653 - loss: 0.1268\n",
      "Epoch 66/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9189 - loss: 0.2156\n",
      "Epoch 67/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9763 - loss: 0.0902\n",
      "Epoch 68/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9623 - loss: 0.0933\n",
      "Epoch 69/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9373 - loss: 0.1597\n",
      "Epoch 70/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9243 - loss: 0.2148\n",
      "Epoch 71/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9384 - loss: 0.1622\n",
      "Epoch 72/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9618 - loss: 0.1233\n",
      "Epoch 73/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9552 - loss: 0.1167\n",
      "Epoch 74/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9568 - loss: 0.1414\n",
      "Epoch 75/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9501 - loss: 0.1349\n",
      "Epoch 76/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9629 - loss: 0.1049\n",
      "Epoch 77/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9622 - loss: 0.1037\n",
      "Epoch 78/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9750 - loss: 0.0734\n",
      "Epoch 79/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9513 - loss: 0.1090\n",
      "Epoch 80/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9642 - loss: 0.0969\n",
      "Epoch 81/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9436 - loss: 0.1295 \n",
      "Epoch 82/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9512 - loss: 0.1115\n",
      "Epoch 83/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9549 - loss: 0.1254\n",
      "Epoch 84/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9726 - loss: 0.1139\n",
      "Epoch 85/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9550 - loss: 0.1144\n",
      "Epoch 86/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9392 - loss: 0.1432\n",
      "Epoch 87/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9680 - loss: 0.1007\n",
      "Epoch 88/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9584 - loss: 0.0950\n",
      "Epoch 89/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9706 - loss: 0.1016\n",
      "Epoch 90/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9658 - loss: 0.0850\n",
      "Epoch 91/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9674 - loss: 0.0930\n",
      "Epoch 92/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9562 - loss: 0.1037\n",
      "Epoch 93/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9517 - loss: 0.1191\n",
      "Epoch 94/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9652 - loss: 0.1000 \n",
      "Epoch 95/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9498 - loss: 0.1044\n",
      "Epoch 96/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9628 - loss: 0.1108\n",
      "Epoch 97/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9560 - loss: 0.1051\n",
      "Epoch 98/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9434 - loss: 0.1508\n",
      "Epoch 99/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9583 - loss: 0.1100\n",
      "Epoch 100/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9578 - loss: 0.0941\n",
      "Epoch 101/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9733 - loss: 0.0851\n",
      "Epoch 102/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9307 - loss: 0.1671\n",
      "Epoch 103/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9505 - loss: 0.1540\n",
      "Epoch 104/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9601 - loss: 0.1196\n",
      "Epoch 105/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9435 - loss: 0.1269\n",
      "Epoch 106/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9708 - loss: 0.0846\n",
      "Epoch 107/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9387 - loss: 0.1635\n",
      "Epoch 108/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9418 - loss: 0.1314\n",
      "Epoch 109/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9576 - loss: 0.0907\n",
      "Epoch 110/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9727 - loss: 0.0736\n",
      "Epoch 111/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9613 - loss: 0.1005\n",
      "Epoch 112/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9590 - loss: 0.1094\n",
      "Epoch 113/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9623 - loss: 0.0773\n",
      "Epoch 114/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9526 - loss: 0.1565\n",
      "Epoch 115/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9344 - loss: 0.1786\n",
      "Epoch 116/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9549 - loss: 0.1124\n",
      "Epoch 117/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9589 - loss: 0.0951\n",
      "Epoch 118/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9723 - loss: 0.0716\n",
      "Epoch 119/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9555 - loss: 0.1210\n",
      "Epoch 120/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9515 - loss: 0.1357\n",
      "Epoch 121/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9770 - loss: 0.0797\n",
      "Epoch 122/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9587 - loss: 0.1008\n",
      "Epoch 123/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9635 - loss: 0.0921\n",
      "Epoch 124/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9728 - loss: 0.0695\n",
      "Epoch 125/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9363 - loss: 0.1565\n",
      "Epoch 126/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9585 - loss: 0.0976\n",
      "Epoch 127/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9563 - loss: 0.0858\n",
      "Epoch 128/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9695 - loss: 0.0803\n",
      "Epoch 129/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9748 - loss: 0.0643\n",
      "Epoch 130/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9617 - loss: 0.0802\n",
      "Epoch 131/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9706 - loss: 0.0896\n",
      "Epoch 132/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9536 - loss: 0.0872\n",
      "Epoch 133/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9669 - loss: 0.0795\n",
      "Epoch 134/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9695 - loss: 0.0753\n",
      "Epoch 135/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9623 - loss: 0.0900\n",
      "Epoch 136/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9709 - loss: 0.0825\n",
      "Epoch 137/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9751 - loss: 0.0683\n",
      "Epoch 138/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9675 - loss: 0.0863\n",
      "Epoch 139/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9713 - loss: 0.0735\n",
      "Epoch 140/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9697 - loss: 0.0696\n",
      "Epoch 141/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9647 - loss: 0.0828\n",
      "Epoch 142/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9810 - loss: 0.0631\n",
      "Epoch 143/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9629 - loss: 0.0838\n",
      "Epoch 144/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9617 - loss: 0.0946\n",
      "Epoch 145/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9771 - loss: 0.0742\n",
      "Epoch 146/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9615 - loss: 0.1061\n",
      "Epoch 147/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9431 - loss: 0.1235\n",
      "Epoch 148/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9590 - loss: 0.1028\n",
      "Epoch 149/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9674 - loss: 0.0687\n",
      "Epoch 150/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9551 - loss: 0.0997\n",
      "Epoch 151/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9685 - loss: 0.0962\n",
      "Epoch 152/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9786 - loss: 0.0614\n",
      "Epoch 153/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9329 - loss: 0.1262 \n",
      "Epoch 154/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9549 - loss: 0.0855\n",
      "Epoch 155/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9612 - loss: 0.0946\n",
      "Epoch 156/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9637 - loss: 0.1181\n",
      "Epoch 157/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9645 - loss: 0.0669\n",
      "Epoch 158/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9743 - loss: 0.0654\n",
      "Epoch 159/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9580 - loss: 0.0819\n",
      "Epoch 160/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9608 - loss: 0.0852\n",
      "Epoch 161/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9603 - loss: 0.0934\n",
      "Epoch 162/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9865 - loss: 0.0530\n",
      "Epoch 163/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9773 - loss: 0.0660\n",
      "Epoch 164/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9640 - loss: 0.0916 \n",
      "Epoch 165/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9597 - loss: 0.0964\n",
      "Epoch 166/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9733 - loss: 0.0691\n",
      "Epoch 167/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9685 - loss: 0.0770\n",
      "Epoch 168/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9713 - loss: 0.0876\n",
      "Epoch 169/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9782 - loss: 0.0537\n",
      "Epoch 170/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9723 - loss: 0.0798\n",
      "Epoch 171/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9734 - loss: 0.0692\n",
      "Epoch 172/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9678 - loss: 0.0884\n",
      "Epoch 173/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9514 - loss: 0.0864\n",
      "Epoch 174/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9556 - loss: 0.0893\n",
      "Epoch 175/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9074 - loss: 0.1702\n",
      "Epoch 176/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9348 - loss: 0.1340\n",
      "Epoch 177/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9460 - loss: 0.1479\n",
      "Epoch 178/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9503 - loss: 0.1606\n",
      "Epoch 179/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9599 - loss: 0.0906\n",
      "Epoch 180/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9540 - loss: 0.1479\n",
      "Epoch 181/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9817 - loss: 0.0576\n",
      "Epoch 182/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9562 - loss: 0.1077\n",
      "Epoch 183/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9519 - loss: 0.0831\n",
      "Epoch 184/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9797 - loss: 0.0679\n",
      "Epoch 185/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9713 - loss: 0.0936\n",
      "Epoch 186/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9690 - loss: 0.0632\n",
      "Epoch 187/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9480 - loss: 0.0925\n",
      "Epoch 188/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9798 - loss: 0.0502\n",
      "Epoch 189/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9678 - loss: 0.0681\n",
      "Epoch 190/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9597 - loss: 0.0800\n",
      "Epoch 191/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9761 - loss: 0.0569\n",
      "Epoch 192/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9645 - loss: 0.0795\n",
      "Epoch 193/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9756 - loss: 0.0634\n",
      "Epoch 194/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9632 - loss: 0.0878\n",
      "Epoch 195/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9746 - loss: 0.0681\n",
      "Epoch 196/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9805 - loss: 0.0591\n",
      "Epoch 197/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9590 - loss: 0.0787\n",
      "Epoch 198/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9744 - loss: 0.0660\n",
      "Epoch 199/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9598 - loss: 0.1029\n",
      "Epoch 200/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9493 - loss: 0.0951\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x20865f2e060>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classificador.fit(previsores_treinamento, classe_treinamento, batch_size = 10, epochs = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-4.49551009e-02,  1.72918409e-01,  2.01586913e-02,\n",
      "        -1.20774090e-01, -3.02031375e-02,  1.39219508e-01,\n",
      "        -1.50718808e-01,  6.43721446e-02, -4.29088444e-01,\n",
      "         5.32514267e-02, -4.12767613e-03,  4.74598398e-03,\n",
      "        -3.12679224e-02,  7.02439621e-02,  4.39343322e-03,\n",
      "         4.21850905e-02],\n",
      "       [ 6.88616792e-03,  1.13908820e-01,  4.79309121e-03,\n",
      "        -6.36052489e-02, -2.45372504e-02, -1.21380277e-01,\n",
      "        -1.20759517e-01,  2.35146824e-02,  6.79687858e-02,\n",
      "         2.99400575e-02, -4.21096295e-01,  4.49069291e-02,\n",
      "        -6.55419379e-02, -1.28392652e-01,  1.95327803e-01,\n",
      "         1.66865531e-02],\n",
      "       [-4.25785519e-02,  3.27231854e-01, -3.52819040e-02,\n",
      "        -1.35323390e-01,  3.04347146e-02,  1.29062817e-01,\n",
      "        -3.46858710e-01,  2.32581630e-01, -3.33958507e-01,\n",
      "        -4.45288382e-02, -1.69078574e-01, -2.37935316e-02,\n",
      "        -4.66402136e-02,  7.84140229e-02,  2.24593394e-02,\n",
      "         5.18272705e-02],\n",
      "       [-2.28677262e-02, -2.11222991e-02, -6.32631555e-02,\n",
      "        -1.06254235e-01, -3.32800783e-02,  5.46370558e-02,\n",
      "        -8.06413516e-02,  2.71365345e-02, -8.38824958e-02,\n",
      "        -2.49042325e-02,  6.08111881e-02, -1.55033835e-03,\n",
      "        -2.67790854e-02,  9.46047008e-02, -4.11349870e-02,\n",
      "        -8.55578408e-02],\n",
      "       [ 5.97877726e-02,  1.01307563e-01,  3.15240063e-02,\n",
      "        -5.83580770e-02, -3.27044241e-02, -4.24481966e-02,\n",
      "         2.41518453e-01,  2.51413435e-01,  3.46787214e-01,\n",
      "        -4.82049258e-03, -7.69968098e-03, -3.96078080e-02,\n",
      "        -1.73315108e-02, -5.93770444e-02, -1.90278087e-02,\n",
      "        -1.17395826e-01],\n",
      "       [ 3.47077884e-02,  2.42291484e-02,  7.74958581e-02,\n",
      "        -1.44609720e-01, -2.74012145e-02,  2.86833525e-01,\n",
      "         2.54860699e-01,  4.71681982e-01,  9.52058509e-02,\n",
      "         1.15569606e-02,  1.35295644e-01, -3.77794653e-02,\n",
      "        -8.53575543e-02,  2.76649594e-02, -9.66089219e-02,\n",
      "        -3.13145459e-01],\n",
      "       [-1.62618365e-02, -1.39855891e-01, -1.16084330e-01,\n",
      "         2.48188954e-02,  2.83297822e-02, -3.28866422e-01,\n",
      "        -7.60431886e-02, -3.76539797e-01, -6.42454543e-04,\n",
      "        -3.74291241e-02,  1.36116534e-01, -3.24515253e-02,\n",
      "         6.76637655e-03, -1.03844307e-01,  1.70661863e-02,\n",
      "         3.99482459e-01],\n",
      "       [-1.02242008e-02,  1.73196286e-01, -7.91975632e-02,\n",
      "        -1.88349877e-02, -8.06511007e-03,  3.21130276e-01,\n",
      "         6.01750016e-02,  3.99162658e-02, -9.79075208e-03,\n",
      "         3.18895504e-02, -3.91429931e-01, -2.23259516e-02,\n",
      "         7.52504021e-02, -3.53523701e-01,  1.51496813e-01,\n",
      "         3.09148490e-01],\n",
      "       [-3.60274501e-02, -6.14590272e-02, -8.86831731e-02,\n",
      "         3.27342749e-01,  3.18838693e-02,  2.94205934e-01,\n",
      "        -4.49004173e-02,  3.14213365e-01, -3.71301919e-02,\n",
      "         3.39207216e-03,  2.62775272e-02, -2.89722886e-02,\n",
      "         1.01916231e-01,  2.87480969e-02,  8.83323103e-02,\n",
      "        -3.31468023e-02],\n",
      "       [ 5.56545109e-02,  2.18516335e-01, -4.58060838e-02,\n",
      "         1.40800904e-02, -1.70959048e-02,  2.36112908e-01,\n",
      "        -1.06447637e-01,  3.28633606e-01, -1.10881224e-01,\n",
      "        -3.66373546e-02, -2.40356058e-01,  1.08899223e-02,\n",
      "         7.31701106e-02,  1.74901098e-01,  2.71157295e-01,\n",
      "         9.85766649e-02],\n",
      "       [-3.86812910e-02, -6.11572564e-02, -6.77209869e-02,\n",
      "         1.93715408e-01,  1.10678179e-02, -5.14043793e-02,\n",
      "         5.09993993e-02,  2.48213977e-01,  2.21757703e-02,\n",
      "        -9.77021456e-03,  4.71860431e-02, -3.50328051e-02,\n",
      "         6.42542541e-03, -1.12851210e-01,  5.78794181e-02,\n",
      "        -8.66716951e-02],\n",
      "       [ 5.29532544e-02,  5.71528859e-02, -5.60833327e-02,\n",
      "        -6.76843757e-03, -1.92680620e-02,  6.09676428e-02,\n",
      "         1.98566020e-02,  2.90046856e-02,  1.28837517e-02,\n",
      "         1.53338374e-03,  4.48691733e-02,  9.21803620e-03,\n",
      "        -8.48517120e-02, -9.08989832e-03, -3.65099646e-02,\n",
      "        -2.62322314e-02],\n",
      "       [-5.70624433e-02, -1.10810352e-02, -5.40214079e-03,\n",
      "        -4.74215904e-03,  3.60180112e-03, -2.10014023e-02,\n",
      "         1.34836854e-02, -3.21632847e-02, -2.28684279e-03,\n",
      "        -3.03242728e-02, -6.72001317e-02, -9.14214551e-03,\n",
      "        -3.27875987e-02, -4.87153837e-03, -9.36246216e-02,\n",
      "         7.18824938e-02],\n",
      "       [-1.37831252e-02,  5.15145920e-02,  7.56015815e-03,\n",
      "        -2.13277154e-02,  1.10561378e-01, -4.86332215e-02,\n",
      "         4.29666042e-03,  1.47367632e-02,  1.02510445e-01,\n",
      "        -9.32328776e-03,  1.40143439e-01, -2.57099364e-02,\n",
      "         9.65590402e-02, -1.67061146e-02, -1.63684897e-02,\n",
      "         7.46010914e-02],\n",
      "       [ 9.19941440e-03, -7.09688589e-02, -3.86715084e-02,\n",
      "        -2.52485514e-01, -1.51847247e-02, -2.12946951e-01,\n",
      "         2.64316291e-01, -1.63557202e-01,  2.42340133e-01,\n",
      "         4.32739817e-02,  1.69596430e-02, -3.98484915e-02,\n",
      "        -1.02073491e-01, -8.37083310e-02, -1.71347540e-02,\n",
      "        -5.06452471e-02],\n",
      "       [ 3.92536551e-01,  4.52572182e-02, -2.05839165e-02,\n",
      "        -2.13781729e-01, -8.90259352e-03,  2.16684148e-01,\n",
      "         2.41676643e-01, -1.25847176e-01,  5.06319463e-01,\n",
      "         1.07426709e-02,  3.47827286e-01, -2.38318183e-02,\n",
      "        -3.22696120e-02, -1.48121983e-01, -1.16678737e-01,\n",
      "         3.99043299e-02],\n",
      "       [-4.11080942e-03,  4.33885545e-01, -4.31423858e-02,\n",
      "         1.69016160e-02,  6.33254694e-03,  7.78466880e-01,\n",
      "        -4.10836875e-01,  1.91574946e-01, -3.30569774e-01,\n",
      "         3.06398943e-02,  4.65500593e-01,  1.33119868e-02,\n",
      "        -1.15618967e-01, -1.18875012e-01, -2.88048834e-01,\n",
      "         1.17393203e-01],\n",
      "       [-1.99517421e-02,  2.70089954e-01, -2.27725450e-02,\n",
      "        -1.69263268e-03,  7.61347264e-03, -1.18449971e-01,\n",
      "         3.38033944e-01,  7.95255780e-01, -5.32739818e-01,\n",
      "        -4.52099517e-02, -5.67646444e-01,  2.11235113e-03,\n",
      "        -5.66854328e-02,  7.50348210e-01,  3.86592209e-01,\n",
      "        -7.69235492e-02],\n",
      "       [-1.01828538e-01, -6.60881042e-01,  1.01641424e-01,\n",
      "        -8.54168907e-02, -8.00596084e-03, -5.30517817e-01,\n",
      "         5.98085642e-01, -4.51652467e-01,  6.91734195e-01,\n",
      "         1.01095876e-02,  4.76286650e-01, -4.53869477e-02,\n",
      "        -8.67041051e-02,  1.87974244e-01, -2.65648798e-03,\n",
      "        -1.95912436e-01],\n",
      "       [-1.92645378e-02, -5.91525137e-01,  4.29613441e-02,\n",
      "        -4.21477333e-02,  2.80650370e-02, -3.67013395e-01,\n",
      "         6.15919948e-01, -4.59328443e-01,  6.23668015e-01,\n",
      "        -5.29133305e-02,  1.21215709e-01, -1.07881390e-02,\n",
      "         2.37761550e-02,  2.09507212e-01,  6.33692294e-02,\n",
      "         3.81870598e-01],\n",
      "       [ 1.05455229e-02,  8.39241520e-02,  1.46312891e-02,\n",
      "        -1.09155409e-01, -2.71832496e-02,  5.31880893e-02,\n",
      "        -6.04708791e-02,  4.92985360e-02, -3.33967537e-01,\n",
      "         3.93759347e-02, -1.24825649e-02, -1.53380316e-02,\n",
      "        -8.02253485e-02,  1.69460606e-02,  3.50010805e-02,\n",
      "        -1.19622517e-02],\n",
      "       [ 6.55779336e-03, -2.81077400e-02,  6.65396750e-02,\n",
      "        -3.56567428e-02,  3.25834863e-02, -3.39210391e-01,\n",
      "         4.97824028e-02, -1.15694270e-01,  2.42170021e-01,\n",
      "        -1.69763751e-02, -4.33982402e-01,  3.15754749e-02,\n",
      "        -2.44704764e-02, -2.07477778e-01,  1.58225372e-01,\n",
      "         6.14586193e-03],\n",
      "       [ 1.68165695e-02,  2.22433016e-01, -5.31041212e-02,\n",
      "        -5.98363616e-02, -5.06036095e-02, -3.86857688e-02,\n",
      "        -2.15647414e-01,  1.41445771e-01, -2.27556407e-01,\n",
      "        -3.39248553e-02, -1.22226596e-01, -4.08914918e-03,\n",
      "        -3.41157727e-02,  6.48902729e-02,  6.89310953e-02,\n",
      "         1.41410800e-02],\n",
      "       [-6.45599961e-02, -6.76648468e-02,  1.76862665e-02,\n",
      "        -8.06902200e-02, -1.80930253e-02, -9.18044299e-02,\n",
      "         1.02843732e-01, -4.68605980e-02,  1.53567091e-01,\n",
      "         2.51862104e-03,  2.45641097e-02, -5.43768108e-02,\n",
      "        -2.55053733e-02,  2.57115122e-02, -2.87151523e-02,\n",
      "        -8.94132331e-02],\n",
      "       [ 1.35258734e-01, -2.43136108e-01, -1.15451306e-01,\n",
      "         5.04676253e-02, -3.29059511e-02, -4.14045900e-01,\n",
      "        -3.55644673e-02, -2.17486039e-01, -5.00595048e-02,\n",
      "        -2.14932319e-02,  5.13696037e-02, -4.48077656e-02,\n",
      "         1.15475386e-01,  1.73819259e-01,  1.71073209e-02,\n",
      "        -2.16622397e-01],\n",
      "       [ 1.59453638e-02, -4.43088487e-02, -1.86103806e-01,\n",
      "         2.33737024e-04,  9.05327091e-04,  1.32332131e-01,\n",
      "         5.13035767e-02, -2.20204711e-01, -2.80390456e-02,\n",
      "         3.93834077e-02,  1.74674764e-01, -1.32867123e-03,\n",
      "        -4.87574004e-02,  2.79797930e-02, -2.19790667e-01,\n",
      "        -5.68300188e-02],\n",
      "       [ 5.72252087e-03,  2.84431912e-02,  3.36015262e-02,\n",
      "         2.63640493e-01, -2.45289877e-02, -1.31819218e-01,\n",
      "        -3.08658481e-01,  9.00627077e-02, -5.21465205e-03,\n",
      "         2.77399272e-02, -1.36688277e-01, -2.58446485e-02,\n",
      "         2.08491281e-01,  1.26292342e-02,  2.06561103e-01,\n",
      "        -3.98605794e-01],\n",
      "       [ 1.28520085e-02, -9.09418613e-02, -7.22992048e-02,\n",
      "         2.18094438e-01, -4.02802452e-02,  3.69558096e-01,\n",
      "        -2.71623194e-01,  3.58225256e-01,  1.29198551e-01,\n",
      "        -1.48788942e-02,  2.65099436e-01,  8.62364005e-03,\n",
      "        -1.24432400e-01, -1.17121547e-01,  2.19512042e-02,\n",
      "        -2.91319609e-01],\n",
      "       [-1.13195973e-02, -3.59470099e-02, -2.92806942e-02,\n",
      "        -2.26675868e-02,  1.62461642e-02,  1.17831929e-02,\n",
      "         5.45278974e-02,  2.67232865e-01,  1.86250694e-02,\n",
      "        -1.62693765e-02,  1.61636636e-01, -5.00130244e-02,\n",
      "        -6.42824546e-02,  3.76060233e-02, -1.65514927e-03,\n",
      "        -2.77975678e-01],\n",
      "       [-8.17292631e-02, -2.56036431e-01,  1.14559755e-02,\n",
      "         2.27969810e-02,  6.20620837e-03, -8.02484825e-02,\n",
      "         3.71298820e-01, -2.84941882e-01,  4.22176152e-01,\n",
      "         4.02120240e-02, -3.25138792e-02, -7.02729973e-04,\n",
      "         7.07695708e-02,  2.74619292e-02,  6.26189634e-02,\n",
      "        -3.38077955e-02]], dtype=float32), array([ 0.01664568,  0.6545076 , -0.1238291 , -0.10436812,  0.03186873,\n",
      "        0.21092391, -0.7300541 ,  0.5258046 , -0.74476075, -0.00469278,\n",
      "       -0.451928  , -0.00153464, -0.02335683,  0.2388675 ,  0.16869749,\n",
      "        0.14582855], dtype=float32)]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "pesos0 = classificador.layers[0].get_weights()\n",
    "print(pesos0)\n",
    "print(len(pesos0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n"
     ]
    }
   ],
   "source": [
    "previsoes = classificador.predict(previsores_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.8622 - loss: 0.5309  \n"
     ]
    }
   ],
   "source": [
    "resultado = classificador.evaluate(previsores_teste, classe_teste)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
