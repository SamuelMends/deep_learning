{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #importando nossa biblioteca Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsores = pd.read_csv('entradas_breast.csv') #declarando nossas variáveis de entrada\n",
    "classe = pd.read_csv('saidas_breast.csv') #declarando nossas variáveis de saida (expectativa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split #Criando os ambientes de treinamento e teste\n",
    "previsores_treinamento, previsores_teste, classe_treinamento, classe_teste = train_test_split(previsores, classe, test_size=0.25) #Declarando as variáveis de treinamento e de teste, em seguida splitando elas através do train_test_slipt, usando test_size = 25, indica que estamos utilizando apenas 25% de todos os registros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samue\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import keras #importando o Keras\n",
    "from keras.models import Sequential #Sequential é a modelo q vamos usar, possui esse nome pois é aformado pela sequência (entrada, primeira camada oculta, segunda camada oculta e saida)\n",
    "from keras.layers import Dense #Dense é o modelo de rede neural densa ou fully connected\n",
    "classificador = Sequential() #nossa rede neural se chama Sequential \n",
    "classificador.add(Dense(units=16, activation='relu', kernel_initializer='random_uniform', input_dim=30)) #Criando nossa primeira camada oculta. Units = Qtde de neuronios de entrada formula (qtde de entradas = 30 + qtde de saidas = 1) e divide por 2. O primeiro activation utilizamos o relu. Initializer é método pelo qual ele vai selecionar as entradas por isso utlizamos random. Input_dim é a qtde de elementos na camada de entrada do programa.\n",
    "classificador.add(Dense(units=16, activation='relu', kernel_initializer='random_uniform')) \n",
    "classificador.add(Dense(units=1, activation='sigmoid')) #Criando nossa camada de saida, units é a qtde de neurônios de saida e actvation nossa função de ativação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#otimizador = keras.optimizers.Adam(learning_rate = 0.001, weight_decay = 0.0001, clipvalue = 0.5)\n",
    "#classificador.compile(optimizer = otimizador, loss = 'binary_crossentropy', metrics= ['binary_accuracy'])\n",
    "classificador.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics= ['binary_accuracy']) #utilizando o otimizador ADAM para fazer o ajuste dos pesos (realiza a otimização da descida do gradiente stocastico). Loss binary crossentropy utilizamos essa função quando trabalhamos apenas com duas classes. Metrics= binary_accuracy para testar a acuracidade da nossa saida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 897us/step - binary_accuracy: 0.5835 - loss: 1.0853 \n",
      "Epoch 2/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 887us/step - binary_accuracy: 0.7964 - loss: 0.4874\n",
      "Epoch 3/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - binary_accuracy: 0.8090 - loss: 0.4263\n",
      "Epoch 4/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step - binary_accuracy: 0.7662 - loss: 0.4490\n",
      "Epoch 5/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.7482 - loss: 0.4119\n",
      "Epoch 6/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.8597 - loss: 0.3240\n",
      "Epoch 7/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.8435 - loss: 0.3567\n",
      "Epoch 8/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.8513 - loss: 0.3389\n",
      "Epoch 9/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.8686 - loss: 0.2815 \n",
      "Epoch 10/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.8905 - loss: 0.2789 \n",
      "Epoch 11/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.8767 - loss: 0.2761 \n",
      "Epoch 12/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.8976 - loss: 0.2548 \n",
      "Epoch 13/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.8540 - loss: 0.3055 \n",
      "Epoch 14/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.8730 - loss: 0.2614 \n",
      "Epoch 15/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.8990 - loss: 0.2266\n",
      "Epoch 16/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9166 - loss: 0.2412\n",
      "Epoch 17/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.8318 - loss: 0.3799 \n",
      "Epoch 18/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.8887 - loss: 0.2665 \n",
      "Epoch 19/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - binary_accuracy: 0.9005 - loss: 0.2480\n",
      "Epoch 20/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - binary_accuracy: 0.9093 - loss: 0.2166\n",
      "Epoch 21/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864us/step - binary_accuracy: 0.9148 - loss: 0.1948\n",
      "Epoch 22/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - binary_accuracy: 0.9112 - loss: 0.2219\n",
      "Epoch 23/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - binary_accuracy: 0.8663 - loss: 0.2833\n",
      "Epoch 24/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - binary_accuracy: 0.9219 - loss: 0.2046\n",
      "Epoch 25/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - binary_accuracy: 0.9421 - loss: 0.1655\n",
      "Epoch 26/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9119 - loss: 0.1868\n",
      "Epoch 27/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - binary_accuracy: 0.8956 - loss: 0.2159\n",
      "Epoch 28/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - binary_accuracy: 0.9178 - loss: 0.2115\n",
      "Epoch 29/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - binary_accuracy: 0.9287 - loss: 0.1734\n",
      "Epoch 30/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9184 - loss: 0.1915 \n",
      "Epoch 31/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - binary_accuracy: 0.9076 - loss: 0.2020\n",
      "Epoch 32/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9111 - loss: 0.1860 \n",
      "Epoch 33/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - binary_accuracy: 0.9185 - loss: 0.1555\n",
      "Epoch 34/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - binary_accuracy: 0.9022 - loss: 0.2233\n",
      "Epoch 35/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - binary_accuracy: 0.9012 - loss: 0.2014\n",
      "Epoch 36/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - binary_accuracy: 0.9346 - loss: 0.1504\n",
      "Epoch 37/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step - binary_accuracy: 0.9311 - loss: 0.1511\n",
      "Epoch 38/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - binary_accuracy: 0.9498 - loss: 0.1399\n",
      "Epoch 39/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - binary_accuracy: 0.9378 - loss: 0.1441\n",
      "Epoch 40/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step - binary_accuracy: 0.9522 - loss: 0.1240\n",
      "Epoch 41/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979us/step - binary_accuracy: 0.9484 - loss: 0.1230\n",
      "Epoch 42/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9487 - loss: 0.1509 \n",
      "Epoch 43/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9384 - loss: 0.1401 \n",
      "Epoch 44/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - binary_accuracy: 0.9261 - loss: 0.1661\n",
      "Epoch 45/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - binary_accuracy: 0.9455 - loss: 0.1247\n",
      "Epoch 46/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - binary_accuracy: 0.9169 - loss: 0.1832\n",
      "Epoch 47/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - binary_accuracy: 0.9470 - loss: 0.1271\n",
      "Epoch 48/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9376 - loss: 0.1229 \n",
      "Epoch 49/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9510 - loss: 0.1268 \n",
      "Epoch 50/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - binary_accuracy: 0.9483 - loss: 0.1228\n",
      "Epoch 51/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - binary_accuracy: 0.9560 - loss: 0.1267\n",
      "Epoch 52/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9195 - loss: 0.1857 \n",
      "Epoch 53/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9429 - loss: 0.1200 \n",
      "Epoch 54/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - binary_accuracy: 0.9388 - loss: 0.1345\n",
      "Epoch 55/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9480 - loss: 0.1095 \n",
      "Epoch 56/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9284 - loss: 0.1409 \n",
      "Epoch 57/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9361 - loss: 0.1117 \n",
      "Epoch 58/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9467 - loss: 0.1263 \n",
      "Epoch 59/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9558 - loss: 0.1464 \n",
      "Epoch 60/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9309 - loss: 0.1433 \n",
      "Epoch 61/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9404 - loss: 0.1516 \n",
      "Epoch 62/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step - binary_accuracy: 0.9327 - loss: 0.1818\n",
      "Epoch 63/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - binary_accuracy: 0.9447 - loss: 0.1355\n",
      "Epoch 64/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9508 - loss: 0.0935 \n",
      "Epoch 65/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9649 - loss: 0.0936 \n",
      "Epoch 66/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9543 - loss: 0.0950 \n",
      "Epoch 67/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - binary_accuracy: 0.9654 - loss: 0.0919\n",
      "Epoch 68/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9318 - loss: 0.1563 \n",
      "Epoch 69/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - binary_accuracy: 0.9611 - loss: 0.0819\n",
      "Epoch 70/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - binary_accuracy: 0.9531 - loss: 0.0967\n",
      "Epoch 71/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979us/step - binary_accuracy: 0.9551 - loss: 0.0943\n",
      "Epoch 72/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9434 - loss: 0.1174 \n",
      "Epoch 73/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9489 - loss: 0.1143 \n",
      "Epoch 74/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - binary_accuracy: 0.9508 - loss: 0.1286\n",
      "Epoch 75/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - binary_accuracy: 0.9563 - loss: 0.0963\n",
      "Epoch 76/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - binary_accuracy: 0.9376 - loss: 0.1205\n",
      "Epoch 77/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 975us/step - binary_accuracy: 0.9611 - loss: 0.1127\n",
      "Epoch 78/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9461 - loss: 0.1368 \n",
      "Epoch 79/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - binary_accuracy: 0.9339 - loss: 0.1293\n",
      "Epoch 80/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9447 - loss: 0.1504 \n",
      "Epoch 81/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9413 - loss: 0.1412 \n",
      "Epoch 82/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9292 - loss: 0.1188 \n",
      "Epoch 83/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - binary_accuracy: 0.9682 - loss: 0.0862\n",
      "Epoch 84/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9462 - loss: 0.1272 \n",
      "Epoch 85/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9318 - loss: 0.1527 \n",
      "Epoch 86/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step - binary_accuracy: 0.9469 - loss: 0.1155\n",
      "Epoch 87/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979us/step - binary_accuracy: 0.9553 - loss: 0.0985\n",
      "Epoch 88/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9557 - loss: 0.1095 \n",
      "Epoch 89/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9608 - loss: 0.0785 \n",
      "Epoch 90/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9171 - loss: 0.1702 \n",
      "Epoch 91/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9769 - loss: 0.0713\n",
      "Epoch 92/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9333 - loss: 0.1533 \n",
      "Epoch 93/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9705 - loss: 0.0754 \n",
      "Epoch 94/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9557 - loss: 0.0789 \n",
      "Epoch 95/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - binary_accuracy: 0.9471 - loss: 0.1128\n",
      "Epoch 96/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9326 - loss: 0.1333 \n",
      "Epoch 97/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9497 - loss: 0.1115 \n",
      "Epoch 98/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9508 - loss: 0.0921 \n",
      "Epoch 99/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9635 - loss: 0.0918 \n",
      "Epoch 100/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9567 - loss: 0.0881 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2d1c43111f0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classificador.fit(previsores_treinamento, classe_treinamento, batch_size = 10, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 1.38307407e-01,  1.01826889e-02, -3.41066539e-01,\n",
      "         4.39980738e-02,  2.20262613e-02,  3.92888822e-02,\n",
      "         7.95838460e-02, -8.93320069e-02,  4.64693122e-02,\n",
      "        -1.67671576e-01,  9.85705480e-03,  9.66156870e-02,\n",
      "        -1.10862404e-01, -2.15376983e-03,  1.19238365e-02,\n",
      "        -1.56687915e-01],\n",
      "       [ 5.73851094e-02, -5.65401912e-02, -7.69448979e-03,\n",
      "         1.26836196e-01, -2.29698077e-01, -5.20138890e-02,\n",
      "         5.11423461e-02, -2.09268227e-01,  4.03991304e-02,\n",
      "        -1.98951185e-01, -8.47031269e-03,  5.01070172e-03,\n",
      "        -3.06099445e-01,  3.47219873e-04, -1.07382433e-02,\n",
      "        -1.46290874e-02],\n",
      "       [ 2.41075605e-01,  6.48688711e-03, -3.13554525e-01,\n",
      "         9.14436430e-02, -1.08039156e-01,  1.42293528e-01,\n",
      "         1.75834224e-01, -2.22694371e-02, -5.76790795e-03,\n",
      "        -7.79856145e-02,  1.31593794e-02,  1.28362030e-01,\n",
      "        -7.92624503e-02, -1.16152130e-02,  3.59964967e-02,\n",
      "        -2.55428433e-01],\n",
      "       [ 7.26564378e-02, -1.06780894e-01, -3.24079320e-02,\n",
      "        -5.21076657e-02,  4.64742184e-02,  2.33973097e-03,\n",
      "         8.13182667e-02,  1.05575090e-02,  1.40112564e-02,\n",
      "         1.26225257e-03, -5.22937588e-02, -1.77664924e-02,\n",
      "         1.98832750e-02, -4.79850844e-02, -2.62609459e-02,\n",
      "        -2.75145676e-02],\n",
      "       [-7.07258284e-02, -6.21357933e-02,  8.49512592e-02,\n",
      "         7.69103784e-03,  1.84872858e-02, -1.52046338e-01,\n",
      "        -8.39430317e-02, -4.00304496e-02, -2.46779341e-02,\n",
      "        -1.77769165e-03, -1.47852981e-02,  2.01768845e-01,\n",
      "        -2.61435863e-02, -3.94670144e-02,  4.09137867e-02,\n",
      "         1.12154603e-01],\n",
      "       [-1.10632047e-01, -4.64512818e-02,  1.75206997e-02,\n",
      "        -1.87719334e-02,  1.41852573e-01, -2.48449847e-01,\n",
      "         2.41781160e-01, -1.80106033e-02,  3.63253690e-02,\n",
      "         7.66484514e-02, -3.51806618e-02,  2.89284527e-01,\n",
      "         1.38541922e-01,  6.87710941e-02,  1.46473227e-02,\n",
      "         9.48151499e-02],\n",
      "       [-1.12467274e-01, -5.59396558e-02,  8.73358473e-02,\n",
      "         3.00668776e-02,  5.02041206e-02,  2.80058295e-01,\n",
      "        -6.75239414e-02, -2.36895531e-02, -4.87402305e-02,\n",
      "         2.21669916e-02,  6.34405017e-02, -8.19980800e-02,\n",
      "         3.66124325e-02,  8.77476111e-03, -5.36540821e-02,\n",
      "        -6.94197463e-03],\n",
      "       [ 8.88535976e-02,  7.07538128e-02, -1.27168998e-01,\n",
      "         1.25803381e-01, -7.97666237e-02, -6.43834770e-02,\n",
      "         8.22807848e-02, -4.22387794e-02,  3.53944264e-02,\n",
      "        -3.94005887e-02, -2.30740961e-02,  5.13637245e-01,\n",
      "        -1.42850205e-01, -1.51987961e-02,  2.26895250e-02,\n",
      "        -1.90205015e-02],\n",
      "       [-2.46639866e-02,  1.49223641e-01,  2.53218766e-02,\n",
      "         5.37516326e-02, -5.17927893e-02, -5.81695028e-02,\n",
      "         1.16797954e-01, -5.08383624e-02, -3.15388702e-02,\n",
      "        -3.37318853e-02,  7.09486529e-02,  2.77019739e-01,\n",
      "        -9.40320566e-02, -3.96776758e-02, -4.81053181e-02,\n",
      "        -3.04813180e-02],\n",
      "       [-8.13393891e-02, -7.55319968e-02, -3.19463879e-01,\n",
      "         3.67650807e-01,  5.99783519e-03,  3.41815362e-03,\n",
      "         8.64817724e-02, -1.91331089e-01,  1.49238080e-01,\n",
      "         2.81076372e-01,  7.00503513e-02, -2.57875733e-02,\n",
      "         2.52623111e-01, -3.52907367e-03, -3.04001905e-02,\n",
      "         4.35374007e-02],\n",
      "       [-6.64930716e-02, -9.56742316e-02,  1.99029800e-02,\n",
      "         1.24765664e-01,  7.94288591e-02, -6.13916889e-02,\n",
      "         6.87412024e-02, -7.09882155e-02,  6.37886813e-03,\n",
      "         5.63240908e-02,  3.14003117e-02,  9.63267908e-02,\n",
      "         2.90321931e-02, -6.53600618e-02,  1.16549041e-02,\n",
      "        -4.89026196e-02],\n",
      "       [ 9.58246458e-03,  2.93225329e-02, -1.09819956e-02,\n",
      "        -5.09419180e-02, -3.78915966e-02, -4.05931249e-02,\n",
      "         1.95881613e-02, -5.09516709e-02, -5.24123870e-02,\n",
      "         2.37530265e-02, -3.43640111e-02,  3.95359807e-02,\n",
      "         3.89507343e-03, -1.15427440e-02, -1.22840507e-02,\n",
      "         2.41056718e-02],\n",
      "       [-6.64178096e-03, -6.40398590e-03,  1.04109440e-02,\n",
      "        -8.60760435e-02, -6.24176189e-02,  4.23268080e-02,\n",
      "        -3.35030332e-02, -3.99577282e-02, -3.72465327e-02,\n",
      "        -5.07129543e-02,  6.09638635e-03,  8.16817861e-03,\n",
      "        -4.87372577e-02, -8.50574393e-03, -2.49559414e-02,\n",
      "         6.98640710e-03],\n",
      "       [-1.91512138e-01, -1.00204192e-01,  8.90759751e-03,\n",
      "        -6.26590922e-02,  1.91836953e-02, -8.75795037e-02,\n",
      "        -3.84624302e-02,  9.91686583e-02, -1.34466914e-02,\n",
      "        -1.39863533e-03, -5.08071072e-02, -6.02259338e-02,\n",
      "         7.61045963e-02,  1.03056014e-01, -3.96753885e-02,\n",
      "         1.02391340e-01],\n",
      "       [ 2.06967324e-01,  4.56922650e-02, -8.96953233e-03,\n",
      "         3.61642167e-02,  4.34333682e-02,  3.93217579e-02,\n",
      "        -3.27849702e-04,  4.68790047e-02, -5.76199256e-02,\n",
      "        -1.31174743e-01,  3.17390449e-02, -7.84739628e-02,\n",
      "        -6.09445460e-02,  2.42098211e-03, -1.65892001e-02,\n",
      "        -5.54351285e-02],\n",
      "       [ 2.01557227e-03,  5.65633997e-02,  7.83308819e-02,\n",
      "        -1.42634675e-01,  3.42686892e-01, -1.84172317e-01,\n",
      "         4.98187095e-02,  3.50073017e-02, -4.81910296e-02,\n",
      "         4.59731258e-02, -9.55566205e-03,  1.13408297e-01,\n",
      "         3.07388961e-01,  3.49637941e-02, -2.89720185e-02,\n",
      "         1.91420466e-01],\n",
      "       [-7.67216533e-02,  3.46327797e-02,  1.17261633e-01,\n",
      "        -1.68493405e-01,  3.45118344e-02, -1.66420173e-02,\n",
      "         6.17661607e-03,  3.36985976e-01,  5.89865027e-03,\n",
      "         5.13709933e-02,  3.43543142e-02, -4.89646494e-02,\n",
      "         6.50901943e-02, -3.66257094e-02,  3.46871763e-02,\n",
      "         1.18536748e-01],\n",
      "       [ 2.95378029e-01,  2.97564380e-02, -2.96870857e-01,\n",
      "         2.36061111e-01, -1.87563464e-01,  9.72023904e-02,\n",
      "         3.40201855e-01, -2.68801808e-01,  4.61070016e-02,\n",
      "        -2.33414188e-01, -7.47126341e-03,  3.02806944e-01,\n",
      "        -2.47800082e-01, -2.22171992e-02, -4.95257266e-02,\n",
      "        -1.94996923e-01],\n",
      "       [ 1.65749803e-01,  2.92947497e-02, -6.23417161e-02,\n",
      "         6.07214160e-02,  3.54044437e-02,  9.49797928e-02,\n",
      "         4.11623865e-01, -7.08189374e-03, -2.41490011e-03,\n",
      "        -5.54559892e-03,  4.05811444e-02, -2.99207754e-02,\n",
      "         2.19186791e-03, -3.51340547e-02,  1.10741975e-02,\n",
      "        -1.48514554e-01],\n",
      "       [-4.18975770e-01, -5.41604720e-02,  4.19510156e-01,\n",
      "        -5.73729277e-02,  2.23374978e-01,  2.58211613e-01,\n",
      "        -2.79265136e-01,  1.36425167e-01, -7.18514472e-02,\n",
      "         1.29767865e-01,  5.75523730e-03, -5.41860282e-01,\n",
      "         1.93756387e-01,  4.56646904e-02,  2.79090200e-02,\n",
      "         4.13891762e-01],\n",
      "       [ 1.04625925e-01, -3.58791836e-02, -1.34014606e-01,\n",
      "         2.69527882e-02, -1.26416892e-01,  5.47967758e-03,\n",
      "         8.15179944e-02, -1.24102429e-01, -5.19910567e-02,\n",
      "        -1.33211032e-01, -7.05197162e-05,  4.34482470e-02,\n",
      "        -1.48389831e-01, -4.71831523e-02,  9.03522223e-03,\n",
      "        -2.52817720e-01],\n",
      "       [-5.36889322e-02, -6.44903108e-02,  1.05898283e-01,\n",
      "         1.37245297e-01, -2.02181488e-01, -1.63291708e-01,\n",
      "        -6.46164566e-02, -1.64202943e-01,  2.55272929e-02,\n",
      "        -2.22227007e-01, -8.30838177e-03, -1.66926965e-01,\n",
      "        -3.09560359e-01, -1.87111814e-02, -2.06458587e-02,\n",
      "         9.37489569e-02],\n",
      "       [ 2.29542717e-01, -6.45871311e-02, -1.91411793e-01,\n",
      "         6.62233904e-02, -7.20119849e-02,  1.01892248e-01,\n",
      "         1.32290959e-01, -7.37646371e-02, -6.24280684e-02,\n",
      "        -8.74250010e-02,  3.56319882e-02,  3.48454202e-03,\n",
      "        -6.29260838e-02,  3.34168002e-02,  8.18436872e-03,\n",
      "        -1.96527109e-01],\n",
      "       [-2.31329892e-02, -7.48545006e-02,  1.16579033e-01,\n",
      "         3.41365556e-03,  3.82742323e-02, -1.00898474e-01,\n",
      "        -3.87772582e-02,  3.08426619e-02, -1.27178626e-02,\n",
      "         6.27131481e-03, -4.58380841e-02, -1.02898456e-01,\n",
      "         6.36885986e-02, -6.31255284e-03, -3.43987681e-02,\n",
      "         1.01704650e-01],\n",
      "       [-3.80982384e-02, -1.58315543e-02,  7.53107592e-02,\n",
      "        -1.56576764e-02, -8.04609209e-02,  1.93940382e-02,\n",
      "        -3.04416984e-01,  1.42898634e-02,  4.78170775e-02,\n",
      "        -5.49688302e-02, -4.17508185e-02, -4.73997325e-01,\n",
      "        -1.59519807e-01, -2.02954076e-02, -4.18381877e-02,\n",
      "        -1.17164485e-01],\n",
      "       [-9.56432745e-02, -3.75416987e-02,  4.08988819e-03,\n",
      "         7.02794418e-02, -3.88703197e-02,  9.63604450e-02,\n",
      "         4.09840792e-02, -9.84629020e-02,  8.12031776e-02,\n",
      "        -9.24813449e-02, -8.20765272e-02,  1.24254197e-01,\n",
      "        -6.49521276e-02,  1.54950786e-02,  1.15244538e-02,\n",
      "         1.94038637e-02],\n",
      "       [-8.66689384e-02, -1.21939771e-01,  2.43045948e-02,\n",
      "         1.12688459e-01, -1.22052833e-01,  5.17001338e-02,\n",
      "         2.34687086e-02, -1.35794938e-01,  3.45539972e-02,\n",
      "        -4.45064567e-02,  2.06316449e-03,  2.18214259e-01,\n",
      "        -1.71472117e-01,  2.62934640e-02,  4.02342752e-02,\n",
      "        -2.11050045e-02],\n",
      "       [-1.24543175e-01,  7.02371001e-02, -6.00974560e-02,\n",
      "        -1.08044796e-01,  1.59212008e-01,  9.18471813e-02,\n",
      "         1.17540054e-01,  6.20217584e-02, -3.13242562e-02,\n",
      "         3.63419354e-02, -7.09438473e-02,  8.72403756e-02,\n",
      "         1.55445069e-01,  3.42501290e-02, -3.00520957e-02,\n",
      "         8.70023482e-03],\n",
      "       [ 4.27958332e-02,  1.14514634e-01,  4.29584347e-02,\n",
      "         2.41107438e-02,  7.44194910e-03, -7.79021606e-02,\n",
      "         3.10544781e-02,  7.10789189e-02,  4.53211889e-02,\n",
      "        -1.81446820e-02, -5.80813829e-03,  1.23854004e-01,\n",
      "        -1.85222812e-02,  4.29176167e-02,  1.69404410e-02,\n",
      "        -1.09859919e-02],\n",
      "       [-2.66025215e-01, -1.00773647e-01,  4.02931154e-01,\n",
      "         1.88750904e-02,  5.49381524e-02, -5.32723516e-02,\n",
      "        -1.58473089e-01, -8.65500793e-03, -2.84539293e-02,\n",
      "         1.37017518e-01, -5.47879701e-03, -2.21462786e-01,\n",
      "         1.33357912e-01, -5.84047707e-03,  1.87099483e-02,\n",
      "         2.60239840e-01]], dtype=float32), array([ 0.58582276,  0.05558122, -0.57887715,  0.13991371, -0.20896341,\n",
      "        0.36441022,  0.36539292, -0.17041332,  0.03063912, -0.2345939 ,\n",
      "        0.0435523 ,  0.25105935, -0.26873198,  0.00339135, -0.00545573,\n",
      "       -0.5343098 ], dtype=float32)]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "pesos0 = classificador.layers[0].get_weights()\n",
    "print(pesos0)\n",
    "print(len(pesos0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n"
     ]
    }
   ],
   "source": [
    "previsoes = classificador.predict(previsores_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.7753 - loss: 0.6034  \n"
     ]
    }
   ],
   "source": [
    "resultado = classificador.evaluate(previsores_teste, classe_teste)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
