{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #importando nossa biblioteca Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsores = pd.read_csv('entradas_breast.csv') #declarando nossas variáveis de entrada\n",
    "classe = pd.read_csv('saidas_breast.csv') #declarando nossas variáveis de saida (expectativa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split #Criando os ambientes de treinamento e teste\n",
    "previsores_treinamento, previsores_teste, classe_treinamento, classe_teste = train_test_split(previsores, classe, test_size=0.25) #Declarando as variáveis de treinamento e de teste, em seguida splitando elas através do train_test_slipt, usando test_size = 25, indica que estamos utilizando apenas 25% de todos os registros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samue\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import keras #importando o Keras\n",
    "from keras.models import Sequential #Sequential é a modelo q vamos usar, possui esse nome pois é aformado pela sequência (entrada, primeira camada oculta, segunda camada oculta e saida)\n",
    "from keras.layers import Dense #Dense é o modelo de rede neural densa ou fully connected\n",
    "classificador = Sequential() #nossa rede neural se chama Sequential \n",
    "classificador.add(Dense(units=16, activation='relu', kernel_initializer='random_uniform', input_dim=30)) #Criando nossa primeira camada oculta. Units = Qtde de neuronios de entrada formula (qtde de entradas = 30 + qtde de saidas = 1) e divide por 2. O primeiro activation utilizamos o relu. Initializer é método pelo qual ele vai selecionar as entradas por isso utlizamos random. Input_dim é a qtde de elementos na camada de entrada do programa.\n",
    "classificador.add(Dense(units=16, activation='relu', kernel_initializer='random_uniform')) \n",
    "classificador.add(Dense(units=1, activation='sigmoid')) #Criando nossa camada de saida, units é a qtde de neurônios de saida e actvation nossa função de ativação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#otimizador = keras.optimizers.Adam(learning_rate = 0.001, weight_decay = 0.0001, clipvalue = 0.5)\n",
    "#classificador.compile(optimizer = otimizador, loss = 'binary_crossentropy', metrics= ['binary_accuracy'])\n",
    "classificador.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics= ['binary_accuracy']) #utilizando o otimizador ADAM para fazer o ajuste dos pesos (realiza a otimização da descida do gradiente stocastico). Loss binary crossentropy utilizamos essa função quando trabalhamos apenas com duas classes. Metrics= binary_accuracy para testar a acuracidade da nossa saida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - binary_accuracy: 0.6024 - loss: 0.9235\n",
      "Epoch 2/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.7346 - loss: 0.4646\n",
      "Epoch 3/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.8417 - loss: 0.3287\n",
      "Epoch 4/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.7771 - loss: 0.4533\n",
      "Epoch 5/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.8709 - loss: 0.3007\n",
      "Epoch 6/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.8575 - loss: 0.2956\n",
      "Epoch 7/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.8966 - loss: 0.2521 \n",
      "Epoch 8/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.8661 - loss: 0.3011 \n",
      "Epoch 9/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9016 - loss: 0.2597\n",
      "Epoch 10/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9074 - loss: 0.2527 \n",
      "Epoch 11/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9180 - loss: 0.2076\n",
      "Epoch 12/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.8812 - loss: 0.2594\n",
      "Epoch 13/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9123 - loss: 0.2217\n",
      "Epoch 14/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.8908 - loss: 0.3317\n",
      "Epoch 15/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.8711 - loss: 0.2501\n",
      "Epoch 16/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9372 - loss: 0.1845\n",
      "Epoch 17/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9079 - loss: 0.2070\n",
      "Epoch 18/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9220 - loss: 0.1939\n",
      "Epoch 19/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.8888 - loss: 0.2351\n",
      "Epoch 20/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.8756 - loss: 0.4074\n",
      "Epoch 21/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9141 - loss: 0.2051\n",
      "Epoch 22/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9226 - loss: 0.1725\n",
      "Epoch 23/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9078 - loss: 0.1762\n",
      "Epoch 24/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9054 - loss: 0.2142\n",
      "Epoch 25/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9153 - loss: 0.2323\n",
      "Epoch 26/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9327 - loss: 0.1475\n",
      "Epoch 27/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9350 - loss: 0.1438\n",
      "Epoch 28/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9142 - loss: 0.2102\n",
      "Epoch 29/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9428 - loss: 0.1662 \n",
      "Epoch 30/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9578 - loss: 0.1143 \n",
      "Epoch 31/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9388 - loss: 0.1558 \n",
      "Epoch 32/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - binary_accuracy: 0.9280 - loss: 0.1671\n",
      "Epoch 33/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9278 - loss: 0.1981 \n",
      "Epoch 34/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9446 - loss: 0.1599 \n",
      "Epoch 35/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9316 - loss: 0.2110\n",
      "Epoch 36/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9395 - loss: 0.1882\n",
      "Epoch 37/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9375 - loss: 0.1553\n",
      "Epoch 38/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9673 - loss: 0.1099\n",
      "Epoch 39/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9390 - loss: 0.1358 \n",
      "Epoch 40/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9418 - loss: 0.1602 \n",
      "Epoch 41/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9159 - loss: 0.2002 \n",
      "Epoch 42/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9222 - loss: 0.1580 \n",
      "Epoch 43/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9394 - loss: 0.1425 \n",
      "Epoch 44/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9470 - loss: 0.1392 \n",
      "Epoch 45/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9485 - loss: 0.1254 \n",
      "Epoch 46/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9350 - loss: 0.1309 \n",
      "Epoch 47/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9421 - loss: 0.1429\n",
      "Epoch 48/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9454 - loss: 0.1391\n",
      "Epoch 49/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9431 - loss: 0.1361\n",
      "Epoch 50/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9348 - loss: 0.1309\n",
      "Epoch 51/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9578 - loss: 0.1156\n",
      "Epoch 52/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9348 - loss: 0.1529\n",
      "Epoch 53/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9360 - loss: 0.1387\n",
      "Epoch 54/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9519 - loss: 0.1348\n",
      "Epoch 55/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9419 - loss: 0.1576\n",
      "Epoch 56/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9692 - loss: 0.0797\n",
      "Epoch 57/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9470 - loss: 0.1244\n",
      "Epoch 58/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9641 - loss: 0.1179\n",
      "Epoch 59/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9484 - loss: 0.1381\n",
      "Epoch 60/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.9398 - loss: 0.1373\n",
      "Epoch 61/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9412 - loss: 0.1071\n",
      "Epoch 62/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9365 - loss: 0.1571\n",
      "Epoch 63/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9472 - loss: 0.1304\n",
      "Epoch 64/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9506 - loss: 0.1188 \n",
      "Epoch 65/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9458 - loss: 0.1584\n",
      "Epoch 66/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9361 - loss: 0.1850\n",
      "Epoch 67/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9405 - loss: 0.1480\n",
      "Epoch 68/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9366 - loss: 0.1492\n",
      "Epoch 69/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9538 - loss: 0.1088\n",
      "Epoch 70/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9200 - loss: 0.1723\n",
      "Epoch 71/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9651 - loss: 0.1175\n",
      "Epoch 72/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9402 - loss: 0.1335\n",
      "Epoch 73/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9565 - loss: 0.1233\n",
      "Epoch 74/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9427 - loss: 0.1249\n",
      "Epoch 75/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9334 - loss: 0.1657\n",
      "Epoch 76/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9413 - loss: 0.1293\n",
      "Epoch 77/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9353 - loss: 0.1748\n",
      "Epoch 78/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9453 - loss: 0.1308  \n",
      "Epoch 79/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9519 - loss: 0.1348 \n",
      "Epoch 80/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9549 - loss: 0.1167 \n",
      "Epoch 81/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9412 - loss: 0.1326\n",
      "Epoch 82/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9430 - loss: 0.1176 \n",
      "Epoch 83/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9256 - loss: 0.1643 \n",
      "Epoch 84/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9195 - loss: 0.1744\n",
      "Epoch 85/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9560 - loss: 0.1264\n",
      "Epoch 86/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9554 - loss: 0.1182\n",
      "Epoch 87/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9506 - loss: 0.1191\n",
      "Epoch 88/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9599 - loss: 0.0825\n",
      "Epoch 89/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9662 - loss: 0.0787\n",
      "Epoch 90/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9664 - loss: 0.0937 \n",
      "Epoch 91/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9112 - loss: 0.2341\n",
      "Epoch 92/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9640 - loss: 0.1218\n",
      "Epoch 93/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9344 - loss: 0.1667\n",
      "Epoch 94/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9294 - loss: 0.1506 \n",
      "Epoch 95/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9660 - loss: 0.0885 \n",
      "Epoch 96/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9405 - loss: 0.1331 \n",
      "Epoch 97/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9432 - loss: 0.1140 \n",
      "Epoch 98/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9564 - loss: 0.1087\n",
      "Epoch 99/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9674 - loss: 0.0910\n",
      "Epoch 100/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9671 - loss: 0.0974\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2318da61c10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classificador.fit(previsores_treinamento, classe_treinamento, batch_size = 10, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-3.36569637e-01, -1.94410041e-01, -2.26900131e-02,\n",
      "        -1.84026845e-02, -4.98589203e-02, -7.41028637e-02,\n",
      "        -2.72026122e-01,  3.32132988e-02,  2.63235092e-01,\n",
      "         3.10836826e-02,  3.37851979e-02,  1.94874972e-01,\n",
      "         2.48188838e-01,  2.16058463e-01,  1.49621278e-01,\n",
      "        -5.90674244e-02],\n",
      "       [ 2.54334360e-02, -1.36319011e-01, -8.30284413e-03,\n",
      "        -1.48027893e-02, -1.06184939e-02, -6.10590614e-02,\n",
      "        -8.45601596e-03,  7.90652074e-03,  1.24908425e-02,\n",
      "         2.47972999e-02,  8.13338920e-05,  6.00228049e-02,\n",
      "         9.01716501e-02,  7.91079849e-02,  6.95537031e-02,\n",
      "        -3.66795734e-02],\n",
      "       [-2.12123200e-01, -1.39898896e-01, -4.50502187e-02,\n",
      "         8.04390665e-03, -6.21252367e-03, -6.20048344e-02,\n",
      "        -2.03686684e-01,  2.41842419e-02,  1.81214347e-01,\n",
      "         3.62795368e-02,  7.61688640e-03,  9.92648602e-02,\n",
      "         1.54863998e-01,  1.22926392e-01,  1.63301200e-01,\n",
      "         1.65830068e-02],\n",
      "       [-5.89137562e-02,  1.81818884e-02, -1.74485762e-02,\n",
      "        -4.15663905e-02, -5.64454123e-02,  1.02516357e-02,\n",
      "        -7.88419470e-02, -4.95765731e-02,  3.44583876e-02,\n",
      "         2.81075854e-02, -3.82873267e-02, -1.18337804e-02,\n",
      "         6.08252957e-02,  2.69684028e-02,  5.23445709e-03,\n",
      "        -6.06278470e-03],\n",
      "       [ 1.35009602e-01,  2.92271748e-02,  3.68064903e-02,\n",
      "        -6.26285970e-02, -3.12671363e-02, -6.27135187e-02,\n",
      "         1.51629135e-01,  3.42124030e-02, -2.00588092e-01,\n",
      "         9.62527469e-02, -1.68640278e-02,  4.24005724e-02,\n",
      "        -2.44806007e-01, -2.47425497e-01,  2.97919065e-01,\n",
      "        -7.42514059e-02],\n",
      "       [-3.73045132e-02,  8.13760459e-02, -2.18205843e-02,\n",
      "        -8.36348219e-04, -7.61195645e-03,  1.81147568e-02,\n",
      "        -6.07758835e-02,  2.66810041e-02,  4.43960511e-04,\n",
      "        -5.46907540e-03,  7.72284865e-02, -5.29918037e-02,\n",
      "         1.01702288e-01,  4.41781543e-02, -1.56324897e-02,\n",
      "        -1.05695268e-02],\n",
      "       [-5.27943810e-03,  3.88478398e-01, -1.27690017e-01,\n",
      "         2.24725576e-03, -2.76795542e-03,  8.45287591e-02,\n",
      "        -5.28522022e-02,  3.33879627e-02, -8.73320177e-02,\n",
      "        -3.27784903e-02,  4.99646999e-02,  9.00007933e-02,\n",
      "         1.32995531e-01,  6.13205023e-02, -2.98530366e-02,\n",
      "        -1.50472298e-02],\n",
      "       [-1.22545809e-01,  7.89113343e-02, -6.22136965e-02,\n",
      "         2.28672903e-02, -1.37250898e-02, -1.29377708e-01,\n",
      "        -1.45102948e-01, -5.23452349e-02,  1.24541141e-01,\n",
      "         1.03285909e-01,  3.44512723e-02,  1.96308821e-01,\n",
      "        -9.23961252e-02, -1.49252698e-01,  2.96044946e-01,\n",
      "         6.57613650e-02],\n",
      "       [-4.35969941e-02,  5.38993366e-02,  7.10669607e-02,\n",
      "         5.20495772e-02, -4.68027452e-03,  6.24500168e-03,\n",
      "        -4.51684594e-02, -4.73777875e-02,  1.41105309e-01,\n",
      "         9.37886909e-02,  6.85344450e-03, -5.47031350e-02,\n",
      "         6.51318729e-02, -1.64790340e-02, -4.09477912e-02,\n",
      "        -5.86790331e-02],\n",
      "       [-2.29817793e-01, -1.53718933e-01,  6.74052536e-02,\n",
      "        -6.79497123e-02, -4.62767333e-02, -3.12397592e-02,\n",
      "        -1.43818483e-01,  4.67002466e-02,  2.69696116e-01,\n",
      "         1.02948979e-01,  9.59573593e-03,  1.71275780e-01,\n",
      "         1.06823668e-01,  1.15758620e-01,  3.24205369e-01,\n",
      "         1.30541712e-01],\n",
      "       [ 3.81766539e-03, -7.07826242e-02, -3.53417359e-02,\n",
      "         7.97699615e-02, -5.36332875e-02,  7.34706372e-02,\n",
      "         6.67095464e-03, -7.45468959e-03, -2.63362210e-02,\n",
      "         4.58940072e-03,  3.98332905e-03, -8.01561698e-02,\n",
      "         4.00645211e-02, -1.36454985e-01,  5.84671870e-02,\n",
      "         6.26643561e-03],\n",
      "       [ 6.47387933e-04, -6.82607526e-03,  6.04623370e-02,\n",
      "        -3.98038663e-02, -2.08891872e-02,  2.81308778e-02,\n",
      "        -1.50046824e-02, -3.19937244e-02,  1.16200289e-02,\n",
      "        -3.94822136e-02, -3.14290472e-03,  6.65254286e-03,\n",
      "        -8.01513195e-02, -7.06091300e-02,  3.62799615e-02,\n",
      "        -2.78420113e-02],\n",
      "       [ 2.37602298e-03, -2.61179563e-02, -5.18932566e-02,\n",
      "         4.00736136e-03,  9.41300672e-03, -7.03500360e-02,\n",
      "         1.73667129e-02, -2.46972106e-02,  6.34180324e-04,\n",
      "        -1.08899288e-02, -2.79313158e-02,  2.01655254e-02,\n",
      "         3.11306678e-03,  6.03072438e-03, -3.41957435e-02,\n",
      "        -3.01214699e-02],\n",
      "       [ 3.55334245e-02,  2.23687980e-02, -3.10020614e-02,\n",
      "        -3.95916961e-02,  6.31522387e-02,  2.42465492e-02,\n",
      "         1.35214493e-01,  6.87806532e-02, -1.45808518e-01,\n",
      "         4.31652134e-03,  7.95768276e-02, -7.23918527e-02,\n",
      "        -7.22619370e-02, -7.53180906e-02,  2.92737409e-02,\n",
      "         1.45464148e-02],\n",
      "       [ 2.67099068e-02, -1.22883037e-01, -1.88154681e-03,\n",
      "        -6.54389635e-02, -8.71017277e-02, -9.18739289e-02,\n",
      "         2.97985394e-02, -5.90748079e-02, -3.98595706e-02,\n",
      "        -3.95421572e-02,  2.18700934e-02,  6.07695542e-02,\n",
      "         1.12570174e-01,  3.46440426e-03,  3.50181088e-02,\n",
      "        -8.10439087e-05],\n",
      "       [ 2.73590088e-01,  6.08848929e-02, -3.32400315e-02,\n",
      "        -4.13938388e-02,  8.29270575e-03,  1.27917290e-01,\n",
      "         1.91622302e-01, -1.36449402e-02, -5.46532534e-02,\n",
      "         6.29723910e-03, -3.64993736e-02, -1.33318861e-03,\n",
      "        -3.98458809e-01, -1.90329671e-01,  1.78414315e-01,\n",
      "        -2.36760844e-02],\n",
      "       [ 9.60182622e-02, -9.16551705e-03, -1.08830303e-01,\n",
      "        -2.38047950e-02, -1.30120700e-03,  1.38275754e-02,\n",
      "         3.02495956e-02, -3.82761434e-02, -3.37482095e-02,\n",
      "        -7.26679619e-03, -2.55377684e-02, -1.48496196e-01,\n",
      "        -1.06774740e-01, -4.59827110e-02, -1.41982213e-02,\n",
      "        -5.75101897e-02],\n",
      "       [-1.36332810e-01, -1.59520462e-01, -2.61794962e-02,\n",
      "         1.95860267e-02,  1.94429066e-02,  4.14030664e-02,\n",
      "        -1.32681459e-01,  2.97627468e-02,  1.51498988e-01,\n",
      "        -1.68940295e-02, -1.48167647e-02,  1.98312908e-01,\n",
      "        -2.60119230e-01, -1.66033030e-01,  2.23842964e-01,\n",
      "        -3.74465063e-02],\n",
      "       [-1.79287001e-01, -2.61417598e-01,  1.61382586e-01,\n",
      "        -3.79751995e-02, -8.44855607e-02, -7.28436606e-03,\n",
      "        -2.95630619e-02,  6.83784997e-03,  1.04751855e-01,\n",
      "         7.20015168e-02, -2.24901475e-02,  3.53701152e-02,\n",
      "         3.64201367e-01,  3.24021578e-01,  2.87037760e-01,\n",
      "         3.91625389e-02],\n",
      "       [ 4.34903502e-01,  3.32773924e-01,  3.22020091e-02,\n",
      "         1.81114860e-02,  6.62439913e-02,  1.97432693e-02,\n",
      "         3.39199126e-01, -1.65166762e-02, -4.00626928e-01,\n",
      "         2.30544209e-02, -3.55758257e-02, -1.82938710e-01,\n",
      "        -2.17444539e-01, -1.20908380e-01, -2.38905832e-01,\n",
      "        -3.26241553e-02],\n",
      "       [-2.48081252e-01,  8.06467794e-03,  3.25010717e-02,\n",
      "         2.57876795e-02, -3.47328298e-02, -5.91754951e-02,\n",
      "        -3.00732255e-02,  4.11855839e-02,  1.15011014e-01,\n",
      "         2.82976236e-02, -3.72229181e-02,  4.86539714e-02,\n",
      "         1.73992336e-01,  1.29751176e-01,  9.03864130e-02,\n",
      "         1.74142383e-02],\n",
      "       [ 1.35152489e-01, -5.01976088e-02, -3.06041464e-02,\n",
      "        -6.72267005e-02, -3.25860195e-02, -8.12542066e-02,\n",
      "         1.26852885e-01,  9.95533448e-03, -1.44701630e-01,\n",
      "         2.85286689e-03, -1.86448842e-02, -5.56898303e-02,\n",
      "        -2.31021792e-02, -3.49287353e-02, -9.68293007e-03,\n",
      "         1.06673772e-02],\n",
      "       [-2.01349288e-01, -7.55033940e-02, -4.68758158e-02,\n",
      "        -4.32124622e-02, -2.12253630e-02, -5.82806058e-02,\n",
      "        -1.70309275e-01, -2.52534822e-02,  1.22512683e-01,\n",
      "        -1.33476825e-02,  1.17263747e-02,  1.16339244e-01,\n",
      "         1.05961464e-01,  1.38394788e-01,  1.06502719e-01,\n",
      "        -4.18415107e-02],\n",
      "       [ 1.20382659e-01,  7.07256943e-02, -6.24776557e-02,\n",
      "        -4.93196398e-02, -3.07816584e-02,  3.38201374e-02,\n",
      "         7.98175558e-02, -1.55702280e-02, -5.35568595e-02,\n",
      "        -4.77016494e-02, -3.41120102e-02, -9.71517265e-02,\n",
      "        -8.03212672e-02, -6.04852326e-02, -3.49970460e-02,\n",
      "         1.15180144e-03],\n",
      "       [ 5.91540188e-02,  1.81477945e-02,  4.96731699e-02,\n",
      "        -8.81893486e-02, -5.73845506e-02, -2.83693336e-02,\n",
      "        -3.58696803e-02,  5.31496219e-02, -1.53121307e-01,\n",
      "        -7.03261942e-02,  6.03404529e-02,  6.04920182e-03,\n",
      "         2.11996660e-02,  9.07551590e-03, -3.07859480e-01,\n",
      "         8.60497449e-03],\n",
      "       [ 1.72655173e-02,  5.06645478e-02,  2.70779934e-02,\n",
      "        -3.75693222e-03, -2.50816923e-02, -1.08260199e-01,\n",
      "        -1.89843457e-02, -6.90643722e-03,  1.20993368e-02,\n",
      "        -2.39679329e-02,  3.54955308e-02, -2.02669576e-02,\n",
      "        -3.64020169e-02, -4.72248206e-03,  8.85531455e-02,\n",
      "        -1.74672939e-02],\n",
      "       [-5.39221875e-02,  1.22095883e-01,  6.24409765e-02,\n",
      "        -3.96727361e-02, -5.01287952e-02, -1.20965831e-01,\n",
      "        -1.00145131e-01,  8.24298803e-03, -2.44135782e-02,\n",
      "         7.13760173e-03, -5.57713863e-03,  2.66566873e-01,\n",
      "        -1.60934851e-02, -1.40702464e-02,  9.99783948e-02,\n",
      "         1.99572127e-02],\n",
      "       [-1.23207120e-03,  1.49546459e-01, -6.45749420e-02,\n",
      "         6.43460837e-04,  9.34965070e-03,  2.51890928e-01,\n",
      "        -1.27350569e-01, -1.82373989e-02,  4.94417385e-04,\n",
      "         6.85440656e-03, -2.28810813e-02,  2.23839849e-01,\n",
      "        -1.12300821e-01, -1.67748198e-01,  1.55780777e-01,\n",
      "        -3.58648971e-02],\n",
      "       [ 3.10411565e-02,  1.21409871e-01,  3.45608145e-02,\n",
      "        -3.33628692e-02, -2.99498718e-02,  2.80674524e-03,\n",
      "        -7.51251401e-03,  3.25874351e-02, -2.51464397e-02,\n",
      "         1.03107933e-02,  1.21235913e-02,  2.44576111e-02,\n",
      "         7.18529597e-02, -9.48839486e-02,  1.79576442e-01,\n",
      "        -2.58459784e-02],\n",
      "       [ 3.90762955e-01,  2.47167438e-01, -3.83931920e-02,\n",
      "        -7.80727491e-02,  7.32633471e-03,  4.78399917e-02,\n",
      "         1.97979644e-01, -1.44200800e-02, -1.79306880e-01,\n",
      "        -2.62048282e-02, -2.68901139e-02, -1.28813878e-01,\n",
      "        -1.43168181e-01, -6.35108277e-02, -1.31970018e-01,\n",
      "         5.03459433e-03]], dtype=float32), array([-0.5323925 , -0.33738503,  0.0206131 , -0.03399377, -0.06136046,\n",
      "       -0.18084799, -0.4331713 ,  0.00159848,  0.44116452,  0.05007102,\n",
      "        0.0110472 ,  0.2901575 ,  0.3806579 ,  0.2920334 ,  0.28526095,\n",
      "        0.0093804 ], dtype=float32)]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "pesos0 = classificador.layers[0].get_weights()\n",
    "print(pesos0)\n",
    "print(len(pesos0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n"
     ]
    }
   ],
   "source": [
    "previsoes = classificador.predict(previsores_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.8519 - loss: 0.8803  \n"
     ]
    }
   ],
   "source": [
    "resultado = classificador.evaluate(previsores_teste, classe_teste)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
